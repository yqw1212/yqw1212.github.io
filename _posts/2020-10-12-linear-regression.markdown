---
layout: post
title:  çº¿æ€§å›å½’
date:   2020-10-12 00:01:01 +0300
image:  2020-10-12-typewriter.jpg
tags:   [MachineLearning]
---

## çº¿æ€§å›å½’

* çº¿æ€§å›å½’(Linear)æ˜¯åˆ©ç”¨æ•°ç†ç»Ÿè®¡ä¸­å›å½’åˆ†æï¼Œæ¥ç¡®å®šä¸¤ç§æˆ–ä¸¤ç§ä»¥ä¸Šå˜é‡é—´ç›¸äº’ä¾èµ–çš„å®šé‡å…³ç³»çš„ä¸€ç§ç»Ÿè®¡åˆ†ææ–¹æ³•ã€‚
* çº¿æ€§å›å½’åˆ©ç”¨ç§°ä¸ºçº¿æ€§å›å½’æ–¹ç¨‹çš„æœ€å°å¹³æ–¹å‡½æ•°å¯¹ä¸€ä¸ªæˆ–å¤šä¸ªè‡ªå˜é‡å’Œå› å˜é‡ä¹‹é—´å…³ç³»è¿›è¡Œå»ºæ¨¡ã€‚è¿™ç§å‡½æ•°æ˜¯ä¸€ä¸ªæˆ–å¤šä¸ªç§°ä¸ºå›å½’ç³»æ•°çš„æ¨¡å‹å‚æ•°çš„çº¿æ€§ç»„åˆã€‚åªæœ‰ä¸€ä¸ªè‡ªå˜é‡çš„æƒ…å†µç§°ä¸ºç®€å•å›å½’å¤§äºä¸€ä¸ªè‡ªå˜é‡æƒ…å†µçš„å«åšå¤šå…ƒå›å½’ã€‚

## çº¿æ€§å›å½’çš„å®é™…ç”¨é€”

* å¦‚æœç›®æ ‡æ˜¯é¢„æµ‹æˆ–è€…æ˜ å°„ï¼Œçº¿æ€§å›å½’å¯ä»¥ç”¨æ¥å¯¹è§‚æµ‹æ•°æ®é›†çš„yå’ŒXçš„å€¼æ‹Ÿåˆå‡ºä¸€ä¸ªé¢„æµ‹æ¨¡å‹ã€‚å½“å®Œæˆè¿™æ ·ä¸€ä¸ªæ¨¡å‹ä»¥åï¼Œå¯¹äºä¸€ä¸ªæ–°å¢çš„Xå€¼ï¼Œåœ¨æ²¡æœ‰ç»™å®šä¸å®ƒç›¸é…å¯¹çš„yçš„æƒ…å†µä¸‹ï¼Œå¯ä»¥ç”¨è¿™ä¸ªæ‹Ÿåˆè¿‡çš„æ¨¡å‹é¢„æµ‹å‡ºä¸€ä¸ªyå€¼ã€‚
* ç»™å®šä¸€ä¸ªå˜é‡yå’Œä¸€äº›å˜é‡X1,â‹¯,ğ‘‹ğ‘,è¿™äº›å˜é‡æœ‰å¯èƒ½ä¸yç›¸å…³ï¼Œçº¿æ€§å›å½’åˆ†æå¯ä»¥ç”¨æ¥é‡åŒ–yä¸Xğ‘—ä¹‹é—´ç›¸å…³æ€§çš„å¼ºåº¦ï¼Œè¯„ä¼°å‡ºä¸yä¸ç›¸å…³çš„Xğ‘—,å¹¶è¯†åˆ«å‡ºå“ªäº›Xğ‘—çš„å­é›†åŒ…å«äº†å…³äºyçš„å†—ä½™ä¿¡æ¯ã€‚

## åº”ç”¨

### èƒŒæ™¯

ä¸æˆ¿ä»·å¯†åˆ‡ç›¸å…³çš„é™¤äº†å•ä½çš„æˆ¿ä»·ï¼Œè¿˜æœ‰æˆ¿å±‹çš„å°ºå¯¸ã€‚æˆ‘ä»¬å¯ä»¥æ ¹æ®å·²çŸ¥çš„æˆ¿å±‹æˆäº¤ä»·å’Œæˆ¿å±‹çš„å°ºå¯¸è¿›è¡Œçº¿æ€§å›å½’ï¼Œç»§è€Œå¯ä»¥å¯¹å·²çŸ¥æˆ¿å±‹å°ºå¯¸ï¼Œè€ŒæœªçŸ¥æˆ¿å±‹æˆäº¤ä»·æ ¼çš„å®ä¾‹è¿›è¡Œæˆäº¤ä»·æ ¼çš„é¢„æµ‹ã€‚

### ç›®çš„

å¯¹æˆ¿å±‹æˆäº¤ä¿¡æ¯å»ºç«‹å›å½’æ–¹ç¨‹ï¼Œå¹¶ä¾æ®å›å½’æ–¹ç¨‹å¯¹æˆ¿å±‹ä»·æ ¼è¿›è¡Œé¢„æµ‹

### æŠ€æœ¯è·¯çº¿

sklearn. linear_model.LinearRegression

### å®ä¾‹æ•°æ®

ä¸ºäº†æ–¹ä¾¿å±•ç¤ºï¼Œæˆäº¤ä¿¡æ¯åªä½¿ç”¨äº†æˆ¿å±‹çš„é¢ç§¯ä»¥åŠå¯¹åº”çš„æˆäº¤ä»·æ ¼ ã€‚
å…¶ä¸­ï¼š

* æˆ¿å±‹é¢ç§¯å•ä½ä¸ºå¹³æ–¹è‹±å°ºï¼ˆft2ï¼‰æˆ¿
* å±‹æˆäº¤ä»·æ ¼å•ä½ä¸ºä¸‡

```assembly
1000,168
792,184
1260,197
1262,220
1240,228
1170,248
1230,305
1255,256
1194,240
1450,230
1481,202
1475,220
1482,232
1484,460
1512,320
1680,340
1620,240
1720,368
1800,280
4400,710
4212,552
3920,580
3212,585
3151,590
3100,560
2700,285
2612,292
2705,482
2570,462
2442,352
2387,440
2292,462
2308,325
2252,298
2202,352
2157,403
2140,308
4000,795
4200,765
3900,705
3544,420
2980,402
4355,762
3150,392
```

### å¯è¡Œæ€§åˆ†æ

* ç®€å•è€Œç›´è§‚çš„æ–¹å¼æ˜¯é€šè¿‡æ•°æ®çš„å¯è§†åŒ–ç›´æ¥è§‚å¯Ÿæˆ¿å±‹æˆäº¤ä»·æ ¼ä¸æˆ¿å±‹å°ºå¯¸é—´æ˜¯å¦å­˜åœ¨çº¿æ€§å…³ç³»ã€‚
* å¯¹äºæœ¬å®éªŒçš„æ•°æ®æ¥è¯´ï¼Œæ•£ç‚¹å›¾å°±å¯ä»¥å¾ˆå¥½çš„å°†å…¶åœ¨äºŒç»´å¹³é¢ä¸­è¿›è¡Œå¯è§†åŒ–è¡¨ç¤ºã€‚

### å®éªŒè¿‡ç¨‹

```assembly
import matplotlib.pyplot as plt
from sklearn import linear_model
import numpy as np

datasets_X = []
datasets_Y = []
fr = open("prices.txt", "r")
lines = fr.readlines() # ä¸€æ¬¡è¯»å–æ•´ä¸ªæ–‡ä»¶
for line in lines:
    items = line.strip().split(",")
    datasets_X.append(int(items[0]))
    datasets_Y.append(int(items[1]))
length = len(datasets_X)
datasets_X = np.array(datasets_X).reshape([length, 1])
# å°†datasets_X è½¬åŒ–ä¸ºæ•°ç»„ï¼Œå¹¶å˜ä¸ºäºŒç»´ï¼Œä»¥ç¬¦åˆçº¿æ€§å›å½’æ‹Ÿåˆå‡½æ•°è¾“å…¥å‚æ•°è¦æ±‚ã€‚
datasets_Y = np.array(datasets_Y)

minX = min(datasets_X)
maxX = max(datasets_X)
X = np.arange(minX, maxX).reshape([-1, 1])
# ä»¥æ•°æ®datasets_X çš„æœ€å¤§å€¼å’Œæœ€å°å€¼ä¸ºèŒƒå›´ï¼Œå»ºç«‹ç­‰å·®æ•°åˆ—ï¼Œæ–¹ä¾¿åç»­ç”»å›¾ã€‚

linear = linear_model.LinearRegression()
linear.fit(datasets_X, datasets_Y, sample_weight=None)
# sample_weight : åˆ†é…ç»™å„ä¸ªæ ·æœ¬çš„æƒé‡ æ•°ç»„ ä¸€èˆ¬ä¸éœ€è¦ä½¿ç”¨ï¼Œå¯çœç•¥ã€‚

# è°ƒç”¨sklearn.linear_model.LinearRegression() æ‰€éœ€å‚æ•°ï¼š
# fit_intercept:å¸ƒå°”å‹å‚æ•°ï¼Œè¡¨ç¤ºæ˜¯å¦è®¡ç®—è¯¥æ¨¡å‹æˆªè·ã€‚å¯é€‰å‚æ•°ã€‚
# normalize:å¸ƒå°”å‹å‚æ•°ï¼Œè‹¥ä¸ºTrueï¼Œåˆ™Xåœ¨å›å½’å‰è¿›è¡Œå½’ä¸€åŒ–ã€‚å¯é€‰å‚æ•°ã€‚é»˜è®¤å€¼ä¸º False ã€‚
# copy_X:å¸ƒå°”å‹å‚æ•°,è‹¥ä¸ºTrue,åˆ™Xå°†è¢«å¤åˆ¶ï¼›å¦åˆ™å°†è¢«è¦†ç›–ã€‚å¯é€‰å‚æ•°ã€‚é»˜è®¤å€¼ä¸ºTrue ã€‚
# n_jobs:æ•´å‹å‚æ•°ï¼Œè¡¨ç¤ºç”¨äºè®¡ç®—çš„ä½œä¸šæ•°é‡ï¼›è‹¥ä¸º1ï¼Œåˆ™ç”¨æ‰€æœ‰çš„CPUã€‚å¯é€‰å‚æ•°ã€‚é»˜è®¤å€¼ä¸º1ã€‚

# æŸ¥çœ‹å›å½’æ–¹ç¨‹ç³»æ•°
print("Coefficients:", linear.coef_)
# æŸ¥çœ‹å›å½’æ–¹ç¨‹æˆªè·
print("intercept:", linear.intercept_)

plt.scatter(datasets_X, datasets_Y, color="red")
plt.plot(X, linear.predict(X), color="blue")
plt.xlabel("Area")
plt.ylabel("Price")
plt.show()
```

show

![]({{site.baseurl}}/img/2020-10-12-show.jpg)

```assembly
Coefficients: [0.14839484]
intercept: 43.92337096187816
```

## å¤šé¡¹å¼å›å½’

* å¤šé¡¹å¼å›å½’(Polynomial Regression)æ˜¯ç ”ç©¶ä¸€ä¸ªå› å˜é‡ä¸ä¸€ä¸ªæˆ–å¤šä¸ªè‡ªå˜é‡é—´å¤šé¡¹å¼çš„å›å½’åˆ†ææ–¹æ³•ã€‚å¦‚æœè‡ªå˜é‡åªæœ‰ä¸€ä¸ªæ—¶ï¼Œç§°ä¸ºä¸€å…ƒå¤šé¡¹å¼å›å½’ï¼›å¦‚æœè‡ªå˜é‡æœ‰å¤šä¸ªæ—¶ï¼Œç§°ä¸ºå¤šå…ƒå¤šé¡¹å¼å›å½’ ã€‚

* ä¸€å…ƒ m æ¬¡å¤šé¡¹å¼å›å½’æ–¹ç¨‹ä¸º
  $$
  y=b0+b1x+b2x^2+â€¦â€¦+bmx^m
  $$

* äºŒå…ƒäºŒæ¬¡å¤šé¡¹å¼å›å½’æ–¹ç¨‹ä¸ºï¼š
  $$
  y=b0+b1x1+b2x2+b3x1^2+b4x2^2+b5x1x2
  $$

* åœ¨ ä¸€å…ƒå›å½’åˆ†æä¸­ï¼Œå¦‚æœä¾å˜é‡yä¸è‡ªå˜é‡xçš„å…³ç³»ä¸ºéçº¿æ€§çš„ï¼Œä½†æ˜¯åˆæ‰¾ä¸åˆ°é€‚å½“çš„å‡½æ•°æ›²çº¿æ¥æ‹Ÿåˆï¼Œåˆ™å¯ä»¥é‡‡ç”¨ä¸€å…ƒå¤šé¡¹å¼å›å½’ã€‚
* å¤šé¡¹å¼å›å½’çš„æœ€å¤§ä¼˜ç‚¹å°±æ˜¯å¯ä»¥é€šè¿‡å¢åŠ xçš„é«˜æ¬¡é¡¹å¯¹å®æµ‹ç‚¹è¿›è¡Œé€¼è¿‘ï¼Œç›´è‡³æ»¡æ„ä¸ºæ­¢ã€‚
* äº‹å®ä¸Šï¼Œå¤šé¡¹å¼å›å½’å¯ä»¥å¤„ç†ç›¸å½“ä¸€ç±»éçº¿æ€§é—®é¢˜ï¼Œå®ƒåœ¨å›å½’åˆ†æä¸­å æœ‰é‡è¦çš„åœ°ä½ï¼Œå› ä¸ºä»»ä¸€å‡½æ•°éƒ½å¯ä»¥åˆ†æ®µç”¨å¤šé¡¹å¼æ¥é€¼è¿‘ ã€‚

## å¤šé¡¹å¼å›å½’çš„åº”ç”¨

### åº”ç”¨èƒŒæ™¯

æˆ‘ä»¬åœ¨å‰é¢å·²ç»æ ¹æ®å·²çŸ¥çš„æˆ¿å±‹æˆäº¤ä»·å’Œæˆ¿å±‹çš„å°ºå¯¸è¿›è¡Œäº†çº¿æ€§å›å½’ï¼Œç»§è€Œå¯ä»¥å¯¹å·²çŸ¥æˆ¿å±‹å°ºå¯¸ï¼Œè€ŒæœªçŸ¥æˆ¿å±‹æˆäº¤ä»·æ ¼çš„å®ä¾‹è¿›è¡Œäº†æˆäº¤ä»·æ ¼çš„é¢„æµ‹ï¼Œä½†æ˜¯åœ¨å®é™…çš„åº”ç”¨ä¸­è¿™æ ·çš„æ‹Ÿåˆå¾€å¾€ä¸å¤Ÿå¥½ï¼Œå› æ­¤æˆ‘ä»¬åœ¨æ­¤å¯¹è¯¥æ•°æ®é›†è¿›è¡Œå¤šé¡¹å¼å›å½’ã€‚

### ç›®çš„

å¯¹æˆ¿å±‹æˆäº¤ä¿¡æ¯å»ºç«‹å¤šé¡¹å¼å›å½’æ–¹ç¨‹ï¼Œå¹¶ä¾æ®å›å½’æ–¹ç¨‹å¯¹æˆ¿å±‹ä»·æ ¼è¿›è¡Œé¢„æµ‹

### æŠ€æœ¯è·¯çº¿

sklearn.preprocessing.PolynomialFeatures

### å®éªŒè¿‡ç¨‹

```assembly
import matplotlib.pyplot as plt
import numpy as np
from sklearn import linear_model
from sklearn.preprocessing import PolynomialFeatures
# å¯¼å…¥çº¿æ€§æ¨¡å‹å’Œå¤šé¡¹å¼ç‰¹å¾æ„é€ æ¨¡å—

datasets_X = []
datasets_Y = []
fr = open("prices.txt", "r")
lines = fr.readlines()
for line in lines:
    items = line.strip().split(",")
    datasets_X.append(int(items[0]))
    datasets_Y.append(int(items[1]))
length = len(datasets_X)
datasets_X = np.array(datasets_X).reshape([length, 1])
datasets_Y = np.array(datasets_Y)

minX = min(datasets_X)
maxX = max(datasets_X)
X = np.arange(minX, maxX).reshape([-1, 1])

poly_reg = PolynomialFeatures(degree=2)
# degree=2è¡¨ç¤ºå»ºç«‹datasets_Xçš„äºŒæ¬¡å¤šé¡¹å¼ç‰¹å¾X_polyã€‚
X_poly = poly_reg.fit_transform(datasets_X)

lin_reg_2 = linear_model.LinearRegression()
lin_reg_2.fit(X_poly, datasets_Y)
# åˆ›å»ºçº¿æ€§å›å½’ï¼Œä½¿ç”¨çº¿æ€§æ¨¡å‹å­¦ä¹ X_polyå’Œdatasets_Yä¹‹é—´çš„æ˜ å°„å…³ç³»ï¼ˆå³å‚æ•°ï¼‰ã€‚

plt.scatter(datasets_X, datasets_Y, color="red")
plt.plot(X, lin_reg_2.predict(poly_reg.fit_transform(X)), color="blue")
plt.xlabel("Area")
plt.ylabel("Price")
plt.show()
```

![]({{site.baseurl}}/img/2020-10-12-poly.jpg)

## å²­å›å½’

### çº¿æ€§å›å½’

å¯¹äºä¸€èˆ¬åœ°çº¿æ€§å›å½’é—®é¢˜ï¼Œå‚æ•°çš„æ±‚è§£é‡‡ç”¨çš„æ˜¯æœ€å°äºŒä¹˜æ³•ï¼Œå…¶ç›®æ ‡å‡½æ•°å¦‚ä¸‹ï¼š
$$
argmin||Xw-y||^2
$$
å‚æ•°wçš„æ±‚è§£ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨å¦‚ä¸‹çŸ©é˜µæ–¹æ³•è¿›è¡Œ
$$
w=(X^TX)^{-1}X^Ty
$$
å¯¹äºçŸ©é˜µXï¼Œè‹¥æŸäº›åˆ—çº¿æ€§ç›¸å…³æ€§è¾ƒå¤§ï¼ˆå³è®­ç»ƒæ ·æœ¬ä¸­æŸäº›å±æ€§çº¿æ€§ç›¸å…³ï¼‰ï¼Œå°±ä¼šå¯¼è‡´ğ‘¿<sup>ğ‘»</sup>ğ‘¿çš„å€¼æ¥è¿‘0ï¼Œåœ¨è®¡ç®— (ğ‘¿<sup>ğ‘»</sup>ğ‘¿)<sup>âˆ’ğŸ</sup>æ—¶å°±ä¼šå‡ºç°ä¸ç¨³å®šæ€§

**ç»“è®ºï¼šä¼ ç»Ÿçš„åŸºäºæœ€å°äºŒä¹˜çš„çº¿æ€§å›å½’æ³•ç¼ºä¹ç¨³å®šæ€§ã€‚**

### å²­å›å½’

å²­å›å½’çš„ä¼˜åŒ–ç›®æ ‡ï¼š
$$
argmin||Xw-y||^2+Î±||w||^2
$$
å¯¹äºçŸ©é˜µæ±‚è§£æ–¹æ³•ä¸º
$$
w=(X^TX+Î±I)^{-1}X^Ty
$$

* å²­å›å½’(ridge regression)æ˜¯ä¸€ç§ä¸“ç”¨äºå…±çº¿æ€§æ•°æ®åˆ†æçš„æœ‰åä¼°è®¡å›å½’æ–¹æ³•
* æ˜¯ä¸€ç§æ”¹è‰¯çš„æœ€å°äºŒä¹˜ä¼°è®¡æ³•ï¼Œå¯¹æŸäº›æ•°æ®çš„æ‹Ÿåˆè¦å¼ºäºæœ€å°äºŒä¹˜æ³• ã€‚

åœ¨sklearnåº“ä¸­ï¼Œå¯ä»¥ä½¿ç”¨sklearn.linear_model.Ridgeè°ƒç”¨å²­å›å½’æ¨¡å‹ï¼Œå…¶ä¸»è¦å‚æ•°æœ‰ï¼š

* alphaï¼šæ­£åˆ™åŒ–å› å­ï¼Œå¯¹åº”äºæŸå¤±å‡½æ•°ä¸­çš„ğœ¶
* fit_interceptï¼šè¡¨ç¤ºæ˜¯å¦è®¡ç®—æˆªè·
* solverï¼šè®¾ç½®è®¡ç®—å‚æ•°çš„æ–¹æ³•ï¼Œå¯é€‰å‚æ•°â€˜autoâ€™ã€â€™svd â€™ã€â€˜sag â€™ç­‰

### äº¤é€šæµé‡é¢„æµ‹å®ä¾‹

#### æ•°æ®ä»‹ç»

æ•°æ®ä¸ºæŸè·¯å£çš„äº¤é€šæµé‡ç›‘æµ‹æ•°æ®ï¼Œè®°å½•å…¨å¹´å°æ—¶çº§åˆ«çš„è½¦æµé‡ã€‚

#### å®éªŒç›®çš„

æ ¹æ®å·²æœ‰çš„æ•°æ®åˆ›å»ºå¤šé¡¹å¼ç‰¹å¾ï¼Œä½¿ç”¨å²­å›å½’æ¨¡å‹ä»£æ›¿ä¸€èˆ¬çš„çº¿æ€§æ¨¡å‹ï¼Œå¯¹è½¦æµé‡çš„ä¿¡æ¯è¿›è¡Œå¤šé¡¹å¼å›å½’ã€‚

#### æ•°æ®å®ä¾‹

æ•°æ®ç‰¹å¾å¦‚ä¸‹ï¼š

* HRï¼šä¸€å¤©ä¸­çš„ç¬¬å‡ ä¸ªå°æ—¶(0~23)
* WEEK_DAYï¼šä¸€å‘¨ä¸­çš„ç¬¬å‡ å¤©(0~6)
* DAY_OF_YEARï¼šä¸€å¹´ä¸­çš„ç¬¬å‡ å¤©(1~365)
* WEEK_OF_YEARï¼šä¸€å¹´ä¸­çš„ç¬¬å‡ å‘¨(1~53)
* TRAFFIC_COUNTï¼šäº¤é€šæµé‡

å…¨éƒ¨æ•°æ®é›†åŒ…å«2ä¸‡æ¡ä»¥ä¸Šæ•°æ®ï¼ˆ21626ï¼‰

#### å®ä¾‹ç¨‹åºç¼–å†™

```assembly
import numpy as np
import pandas as pd
from sklearn.linear_model import Ridge
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures

data = pd.read_csv("data.csv", encoding="gbk")
data = np.array(data)

X = data[:, 1:5]
# Xç”¨äºä¿å­˜0~3ç»´æ•°æ®ï¼Œå³å±æ€§
y = data[:, 5]
# yç”¨äºä¿å­˜ç¬¬ 4 ç»´æ•°æ®ï¼Œå³è½¦æµé‡
poly = PolynomialFeatures(6)
# ç”¨äºåˆ›å»ºæœ€é«˜æ¬¡æ•° 6 æ¬¡æ–¹çš„çš„å¤šé¡¹å¼ç‰¹å¾ï¼Œå¤šæ¬¡è¯•éªŒåå†³å®šé‡‡ç”¨6æ¬¡
X = poly.fit_transform(X)
# Xä¸ºåˆ›å»ºçš„å¤šé¡¹å¼ç‰¹å¾

train_set_X, test_set_X, train_set_y, test_set_y = train_test_split(X, y, test_size=0.3, random_state=0)
# test_size è¡¨ç¤ºæµ‹è¯•é›†çš„æ¯”ä¾‹,random_state æ˜¯éšæœºæ•°ç§å­

clf = Ridge(alpha=1.0, fit_intercept=True) # åˆ›å»ºå²­å›å½’å®ä¾‹
clf.fit(train_set_X, train_set_y)
clf.score(test_set_X, test_set_y)
# åˆ©ç”¨æµ‹è¯•é›†è®¡ç®—å›å½’æ›²çº¿çš„æ‹Ÿåˆä¼˜åº¦ï¼Œ clf.score è¿”å›å€¼ä¸º 0.7375
# æ‹Ÿåˆä¼˜åº¦ï¼Œç”¨äºè¯„ä»·æ‹Ÿåˆå¥½åï¼Œæœ€å¤§ä¸º 1 ï¼Œæ— æœ€å°å€¼ï¼Œ
# å½“å¯¹æ‰€æœ‰è¾“å…¥éƒ½è¾“å‡ºåŒä¸€ä¸ªå€¼æ—¶ï¼Œæ‹Ÿåˆä¼˜åº¦ä¸º 0

start = 200
end = 300
y_pre = clf.predict(X) # æ˜¯è°ƒç”¨ predict å‡½æ•°çš„æ‹Ÿåˆå€¼
time = np.arange(start, end)
plt.plot(time, y[start:end], "b", label="real")
plt.plot(time, y_pre[start:end], "r", label="predict")
# å±•ç¤ºçœŸå®æ•°æ®ï¼ˆè“è‰²ï¼‰ä»¥åŠæ‹Ÿåˆçš„æ›²çº¿ï¼ˆçº¢è‰²ï¼‰
plt.legend(loc="upper left") # è®¾ç½®å›¾ä¾‹çš„ä½ç½®
plt.show()
```

![]({{site.baseurl}}/img/2020-10-12-traffic.jpg)