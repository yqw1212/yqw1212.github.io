---
layout: post
title:  Operating System
date:   2021-06-16 00:01:01 +0300
image:  2021-06-16-woman.jpg
tags:   [note]
---

### 导论

计算机系统可以分为4个组成部分

* 计算机硬件
* 操作系统
* 系统程序
* 用户

计算机系统的组成包括硬件、软件和数据。

操作系统是一直运行在计算机上的程序，通常称为内核。

### 计算机系统结构

中断处理：

* 操作系统通过存储寄存寄存器和程序计数器来维护 CPU 的状态。

* 确定已发生哪种类型的中断。
* 代码的单独部分确定应针对每种类型的中断执行哪些操作。
* 返回到操作系统中保存的状态或其他部分。

当I/O设备需要服务时会产生中断。发生中断时，操作系统首先确定哪个I/O设备引起中断。接着它会查找I/O设备表，以确定该设备状态，并修改表条目，以反映出现了中断。对于绝大多数设备，中断表示I/O请求的完成。如果队列中还有其他请求等待该设备，那么操作系统开始处理下一个请求。

#### 存储结构

DMA（直接内存访问）

用于能够以接近内存速度传输信息的高速 I/O 设备。

存储层次之间的信息移动可以是显示的，也可以是隐式的，这取决于硬件设计和所控制的操作系统软件。例如，高速缓存到CPU和寄存器之间的数据传输通常为硬件功能，无需操作系统的干预。另一方面，磁盘到内存的数据传输通常是由操作系统控制的。

**一致性**

#### I/O保护

用户程序执行系统呼叫，请求操作系统代表其执行 I/O。 操作系统以监视器模式执行，检查请求是否有效，并且（如果请求有效）执行 I/O 请求。 然后，操作系统返回给用户。

#### 内存保护

为了保护内存，添加两个寄存器，以确定程序可能访问的合法地址的范围：

* Base（基址）寄存器：持有最小的合法物理存储地址。

* Limit（界）寄存器：包含范围的大小。

#### CPU保护

Load-timer is a privileged instruction

### 操作系统结构

#### 操作系统组件

##### 保护

保护是一种控制进程或用户对计算机系统资源的访问的控制。

##### Command-interpreter

命令解释器是用户和操作系统之间的接口。基于字符和基于GUI的解释器。

#### 操作系统服务

程序执行–系统将程序加载到内存并运行它的能力。

I/O 操作 - 由于用户程序无法直接执行 I/O 操作，操作系统必须提供执行 I/O 的某些方法。

文件系统操作–程序读取、编写、创建和删除文件的能力。

通信——在同一台计算机上执行的过程之间或在网络捆绑在一起的不同系统上交换信息。通过共享内存或消息传递实现。

错误检测–通过检测CPU和内存硬件、I/O设备或用户程序中的错误来确保正确的计算。

资源分配–将资源分配给多个用户或多个同时运行的工作。

统计-跟踪和记录哪些用户使用多少和什么样的计算机资源用于帐户计费（计算）或积累使用统计。

保护–确保控制对系统资源的所有访问。链条只有最薄弱的环节才能强大

#### 操作系统API（系统调用）

系统调用提供了操作系统提供的有效服务界面。

使用三种一般方法在运行程序和操作系统之间传递参数。

* 在寄存器中传递参数。

* 将参数存储在表中以内存中，表地址作为寄存器中的参数传递。
* 按程序将参数推送（存储）到堆栈上，然后通过操作系统弹出堆栈。

系统调用的种类

* 过程控制
* 文件管理
* 设备管理
* 信息维护
* 通信

##### 系统程序

命令解释程序

* 可以包含代码段
* 或调用公用文件执行命令。

绝大多数用户所看到的操作系统是由系统程序而不是实际系统调用定义的。

##### 操作系统结构

最初的UNIX操作系统由两个可分离的部分组成：

* 系统程序
* 内核

**微内核**

将所有非基本部分从内核中移走，并将它们实现为系统程序或用户程序。微内核的优点还包括简化了对操作系统功能的扩充。向用户空间中添加的所有的新服务都不需要修改内核。必须修改内核时，改变造成的影响更小，因为微内核是一个更小的内核。这样，操作系统更易于移植。

**虚拟机**

好处

* 通过完全保护系统资源，虚拟机提供了一个坚实的安全层
* 虚拟机允许进行系统开发而不必中断正常的系统操作

但虚拟机概念很难提供真实的硬件效果

### 进程

#### 概念

两个或两个以上的进程可能与同一程序相关联。一个进程可以生成新进程。

进程包括：

* 程序代码
* 
* 程序计数器值和处理器寄存器的内容
* 堆栈部分和数据部分

**PCB进程控制块**

* 进程状态
* 程序计数器
* CPU寄存器
* CPU调度信息
* 内存管理信息
* 记账信息
* I/O状态信息

多道程序设计的度：内存中的进程数量。

##### 进程操作

三种资源共享方式

* 父进程与子进程共享所有资源
* 子进程共享父进程中的部分资源
* 父进程与子进程不共享任何资源

当进程创建新进程时，有两种执行可能

* 父进程与子进程并发执行
* 父进程等待，直到某个或全部子进程执行完毕

##### 进程通信

**IPC进程间通信机制**

共享内存

Producer process

```assembly
item nextProduced;
while (1) {
	while(((in + 1)%BUFFER_SIZE) == out)
		; /* do nothing */
	buffer[in] = nextProduced;
	in = (in + 1) % BUFFER_SIZE;
}
```

Consumer Process

```assembly
item nextConsumed;
while (1) {
	while (in == out)
		; /* do nothing */
	nextConsumed = buffer[out];
	out = (out + 1) % BUFFER_SIZE;
}
```

### 线程

在OS中引入线程，是为了减少程序在并发执行时所付出的**时空开销**，使OS具有更好的**并发性**。

进程特性：

* 进程是一个**可拥有资源**的独立单元

* 进程同时又是一个**可独立调度**和**分派**的基本单元

为了程序能并发执行，系统还必须进行以下的**一系列操作**：

* **创建进程**
* **撤销进程**
* **进程切换**

线程，有时称轻量级进程LWP，是**CPU使用的基本单元**；它由线程ID、程序计数器、寄存器集合和堆栈组成。它与属于同一进程的其它线程共享其代码段、数据段和其他操作系统资源。

一个传统进程只有单个控制线程。如果进程有多个控制线程，那么它能同时做多个任务。

多线程编程的优点：

* 响应度高

  多个线程分别处理相应事件，如多线程网页浏览器在用一个线程装入图像时，能通过另一个线程与用户交互。

* 资源共享

  线程默认共享它们所属进程的内存和资源。

* 经济

  进程创建所需的**内存和资源**的分配比较昂贵。由于线程能共享它们所属进程的资源，所以**线程创建和上下文切换**会更为经济。

* 多处理器体系结构的利用

  能充分使用多处理器体系结构，以便每个线程能并行运行在不同的处理器上。

用户线程在**内核之上**支持，并在用户层通过**线程库**来实现。线程库提供对线程创建、调度和管理的支持而无需内核支持。优点：能快速创建和管理。

内核线程由**操作系统**直接支持：内核在其空间内执行线程创建、调度和管理。内核线程的创建和管理通常要**慢于**用户线程的创建和管理。

用户线程：如果**内核是单线程**的，那么任何一个用户级线程若执行阻塞系统调用就会引起**整个进程阻塞**，即使还有其他线程可以在**应用程序**内执行。

内核线程：由于内核管理线程，当一个线程执行阻塞系统调用时，内核能调度应用程序内的另一个线程以便执行。

#### 三种模型

* 多对一

  多对一模型将许多用户级线程映射到一个内核线程。**线程管理在用户空间进行**，因而效率比较高，但是如果一个线程执行了阻塞系统调用，那么整个进程就会**阻塞**。因为任一时刻只有一个线程能访问内核，多个线程不能并行运行在**多处理器**上。

  在不支持内核级线程的操作系统上所实现的用户级线程库也使用了多对一模型。

* 一对一

  每个用户线程映射到一个内核线程。该模型在一个线程执行**阻塞**系统调用时，能允许另一个线程继续执行，所以它提供了比多对一模型更好的并发功能；它也允许多个线程能并行地运行在**多处理器**系统上。

  缺点是：创建一个用户线程就需要创建一个相应的内核线程。由于创建内核线程的开销会影响应用程序的性能，所以这种模型的绝大多数实现限制了系统所支持的线程数量。

* 多对多

  多对多模型**多路复用**了许多用户级线程到同样数量或更小数量的内核线程上。

  多对多模型中，开发人员可以创建任意多的必要用户线程，并且相应内核线程能在多处理器系统上并行执行。一个线程执行阻塞系统调用时，内核能调度另一个线程来执行。

### CPU调度

**多道程序设计的目标**是在任何时候都有一个进程在运行，以使CPU使用率最大化。

调度是操作系统的基本功能。几乎所有计算机资源在使用前都要被调度。当然，CPU是最为重要的计算机资源之一。**因此，CPU调度对操作系统设计来说非常重要。**

每当CPU变为空闲时，操作系统就必须从就绪队列中选择一个进程来执行。进程选择由**短期调度程序**执行。调度程序从内存中就绪可执行的进程里选择一个，并为其中之一分配CPU。

短期调度频繁地为CPU选择新进程，通常每100ms至少执行一次。由于每次执行之间的时间较短，**短期调度程序必须要快**。如果需要10ms来确定执行一个运行100ms的进程，那么10/(100+10)=9%的CPU时间会仅仅用于（或浪费在）调度工作上。

##### 分配程序

将CPU的控制权交给由短期调度程序选择的进程

##### 分派延迟

分配程序停止一个进程而启动另一个所要花的时间

#### 标准

不同的**CPU调度算法**具有不同属性，且可能对某些进程更为有利。为了选择算法以适用于特定情况，必须分析各个算法的属性。为在不同算法之间进行比较，分析员提出了许多准则：

* CPU使用率：需要使CPU尽可能忙，对真实系统，它应从**40%到90%**
* 吞吐量：一个时间单元内所完成进程的数量
* 周转时间：**从进程提交到完成的时间间隔，是所有时间段之和**，包括等待进入内存、在就绪队列中等待、在CPU上执行和I/O执行
* 等待时间：进程在就绪队列中等待时间之和
* 响应时间：从提交请求到产生第一响应时间。

人们需要使CPU使用率和吞吐量最大化，而使周转时间、等待时间和相应时间最小化。

在绝大多数情况下，要优化平均度量值。不过，在有的情况下，需要优化最小值或最大值，而不是平均值。

#### 调度算法

##### 先到先服务调度

护航效果（convoy effect）：所有其他进程都等待一个大进程释放CPU，导致CPU和设备的使用率变得更低。

FSFC算法对于分时系统是尤为麻烦的。允许一个进程持有CPU的时间过长，将是个严重错误。

##### 最短作业优先调度

最短作业优先调度：将每个进程与其下一个CPU区间相关联。当CPU为可用时，它会赋给具有最短后续CPU区间的进程。如果两个进程具有同样长度的CPU区间，那么可以使用FCFS调度来处理。

两种方式

* 非抢占式：一旦进程获得CPU就一直占据CPU，直到其CPU区间完成为止

* 抢占式：如果一个新来的进程其CPU区间小于当前进程的CPU区间，则抢占之。这种调度方式称为最短剩余时间作业优先（Shortest Remaining Time First, SRTF）

SJF是最佳的：对于给定的一组进程，SJF算法的平均等待时间最小。

下一个CPU区间的长度通常可预测为以前CPU区间的测量长度的指数平均
$$
τ_{n+1}=αt_n+(1-α)τ_n
$$

##### 优先权调度

饥饿——低优先级进程可能永远不会执行

老化——随时间降低优先级

##### 转轮法调度

可能存在两种情况：

* 进程可能只需要小于一个时间片的CPU区间。此时，进程本身会自动释放CPU。调度程序接着会处理就绪队列的下一个进程。

* 当前运行进程的CPU区间比一个时间片要长，定时器会中断并产生操作系统中断。进行上下文切换，该进程会被加入到就绪队列的尾部。接着，CPU调度程序会选择就绪队列中的下一个进程

如果就绪队列中有n个进程，具时间片为q，则每个进程会得到1/n的CPU时间，每个长度不超过q时间单元。每个进程必须等待CPU的时间不会超过(n-1)q个时间单元，直到它的下一个时间片为止。

周转时间也时间片的依赖于大小，通常，如果绝大多数进程能在一个时间片内结束其下一个CPU区间，那么平均周转时间会有所改善。

##### 多级队列调度

对于多级队列调度算法，通常进程进入系统时，**被永久地分配到一个队列**。进程并不在可队列之间移动。这种设置的优点是**低调度开销**，缺点是不够灵活。

##### 多级反馈队列调度

如果进程使用过多的 CPU 时间，则将移动到更低优先级的队列。

在低优先级队列中等待时间过长的进程可能会移动到更高优先级的队列。

#### 多处理器调度

同构：处理器**功能相同**的系统，任何可用处理器都可用于运行队列内的任何进程。

异构：只有是给定处理器指令集编译的程序才能运行在该处理器上

通用内存访问 vs 非通用内存访问

如果有多个相同处理器可用，那么可进行**负载分配**。**有可能为每个处理器提供独立的队列**。而在这种情况下，一个具有空队列的处理器会空闲，而另一个处理器会很忙。为了阻止这种情况，可使用**一个共同就绪队列**。所有进程都进入这一队列，并被**调度**到任何可用空闲处理器上。

对于这种情况，有两种调度方法可使用。一种方法是，每个处理器是**自我调度**的。每个处理器都检查共同就绪队列，并选择一个进程执行。另一个方法可以避免这个问题，即选择一个处理器来为其他处理器进行调度，因此创建了**主从结构**。

有的系统将这一结构做了进一步拓展，采用单一处理器即**主服务器**，以处理所有**调度决策、I/O处理和其他系统活动**。**其他处理器**只执行用户代码。这种非对称多处理比对称处理更为简单，因为只有一个处理器访问系统数据结构，减轻了数据共享的需要。然而，它的效率并不高。I/O为主进程可能使执行所有I/O操作的那个CPU成为瓶颈。

#### 实时调度

**硬实时系统**需要在保证的时间内完成关键性的任务。

**硬实时系统**由运行在专用于关键进程的硬件上的特殊目的软件组成，因而缺乏现代计算机和操作系统的全部功能。

**软实时系统**能够容忍一定程度的时间延迟及其引起的服务质量下降的实时系统。

实现软实时功能要求仔细设计**调度程序**和**操作系统**有关方面。

第一，系统必须有优先权调度，且实时进程必须有最高的优先权。实时进程的优先权不能随时间而下降，尽管非实时进程的优先权可以。

第二，分派延迟必须小。延迟越小，实时进程在能运行时就可越快开始运行。

#### 算法评估

##### 确定性建模

采用特定预先确定的负荷，定义在给定负荷下每个算法的性能。

用途：描述调度算法和提供例子。

简单快速，给出了确切数字，以允许算法被比较。但通常过分特殊且要求**过多精确知识**，故用处有限

##### 排队模型

计算机系统可描述为服务器网络。每个服务器都有一个等待进程队列。CPU是具有就绪队列的服务器，而I/O系统具有设备队列。知道了到达率和服务率，就可以计算使用率、平均队列长度、平均等待时间等。这种研究领域称为排队网络分析。

排队分析可用于比较调度算法，但它也有限制。可以处理的算法和分布种类还是比较有限的。复杂算法或分布的数学分析可能难于处理。

设n 为平均队列长度，W 为队列中的平均等待时间，λ 为新进程到达队列的平均到达速率（如三个进程每秒）。那么，希望在进程等待的W时间内，有λ × W 个新进程到达队列。如果系统处于稳定的状态，那么离开队列的进程数量必须等于到达队列的进程数量。这样：
$$
n = λ × W
$$
这个公式被称为**Little公式**（Little's formula）。Little公式非常有用，它适用于任何调度算法和到达分布情况。

如果已知Little公式中两个变量的值，就可以利用利特尔公式计算第三个变量。例如，如果我们知道平均每秒到达7 个进程，队列中通常有14 个进程，那么我们可以计算出平均等待时间是每个进程2 秒。

##### 模拟

为了获得对调度算法更为精确的评估，可使用模拟。

模拟涉及对计算机系统模型进行程序设计。

* 通过软件数据结构表示系统主要组成部分。

* 模拟程序有一个变量以代表时钟；当该变量的值增加时，模拟程序会修改系统状态已反映设备、进程和调度程序的活动。

* 随着模拟程序的执行，用以表示算法性能的统计数字可以被收集并打印出来。

有用但是成本高。

##### 实现

即使模拟其精确度也是有限的。针对评估调度算法，惟一完全精确的方法是：

* 对它进行程序编码
* 将其放在操作系统内
* 观测它如何工作。

主要困难是这种方法的代价：对算法编码、修改操作系统以支持该算法；用户对不断变化的操作系统的反应；另一困难是算法所使用的环境会变化

### 进程同步

共享数据的并发访问可能导致数据的不一致，维护数据的一致性需要能够保证协作进程顺序执行的机制

原子操作是指不间断地完成全部操作的操作。

多个进程并发访问和操作同一数据且执行结果与访问发生的特定顺序有关，称为**竞争条件**。共享数据的最终值取决于哪个过程最后完成。

为了防止上述竞争条件，需要确保一段时间内只有一个进程能操作变量。为了实现这种保证，要求一定形式的进程间同步。

临界区问题的解答必须满足三项要求：

* **互斥**（Mutual Exclusion）：如果进程Pi在其临界区执行，那么其他进程都不能在其临界区内执行。

* **有空让进**（Progress）：如果没有进程在其临界区内执行且有进程希望进入临界区，那么只有那些不在剩余区内执行的进程能参加决策，以选择谁能下一个进入临界区，且这种选择不能无限推迟。

* **有限等待**（Bounded Waiting）：在一个进程做出进入其临界区的请求到该请求被允许期间，其他进程被允许进入期临界区的次数存在一个上限。

算法一

```assembly
int i = 0 or 1;    
int j = 1-i;
int turn;     // initially turn = 0
turn = i;     // Pi can enter its critical section
do{	
	while (turn != i) ;
		critical section
	turn = j;
		reminder section
}while(1);
```

算法二

Process *Pi*

```assembly
boolean flag[2];  // initially flag[0] = flag[1] = false.
flag[i] = true;    // Intention: Pi ready to enter its critical section
do{
	flag[i] = true;
    while(flag[j]);
    	critical section
	flag[i] = false;
		remainder section
}while(1);
```

算法三（Peterson算法）

```assembly
int turn;
boolean flag[2];
do{
	flag[i] = true;
    turn = j;
    while(flag[j] and turn==j);
		critical section
	flag[i] = false;
		remainder section
}while(1);
```

蛋糕店算法

```assembly
boolean choosing[n]; // false
int    number[n]; // 0
do { 
	choosing[i] = true;
	number[i] = max(number[0], number[1], …, number[n – 1])+1;
	choosing[i] = false;

	for(j = 0; j < n; j++) {
		while(choosing[j]) ; 
		while((number[j] != 0) && (  (number[j],j) < (number[i],i)  ) );
	}
		critical section
	number[i] = 0;
		remainder section
}while(1);
```

#### 硬件方法

许多系统提供了临界区代码的硬件支持

单处理器系统 － 可以禁用中断，当前正在执行的代码可以顺利执行而不会被抢占。

在多处理器环境下，这种解决方案是不可行的。

现代机器提供了特殊的原子硬件指令

原子 = 不可中断的

* TestAndSet指令

* Swap指令（交换内存中两个字的内容）

TestAndSet

```assembly
boolean TestAndSet(boolean &target) {
	boolean rv = target;
	target = true;
	return rv;
}

```

Mutual exclusion 

nProcess *Pi*

```assembly
boolean lock = false;
do{
	while(TestAndSet(lock));
		critical section
	lock = false;
		remainder section
}
```

Swap: Mutual exclusion 

nProcess *Pi*

```assembly
boolean lock=false;
do{
	key = true;
	while(key == true) Swap(lock,key);
		critical section
	lock = false;
		remainder section
}
```

Bounded-waiting mutual exclusion with TestAndSet

```assembly
boolean waiting[n];
boolean lock;

do{ 
    waiting[i] = true; key = true;
    while (waiting[i] && key) key = TestAndSet(lock);
    waiting[i] = false;
        critical section
    j = (i+1)%n;
    while ((j != i) && !waiting[j] ) j = (j+1) % n;
    if (j==i) lock = false;
    else waiting[j] = false;
        remainder section
} while(1);
```

这些数据结构的初始值为false。为了证明满足互斥要求，注意到只有waiting[i]==false或key==false时，进程pi才进入其临界区。只有当TestAndSet执行时，key的值才变为false。执行TestAndSet的第一个进程会发现key==false；所有其他进程必须等待。只有其他进程离开其临界区时，变量waiting[i]的值才能变为false；每次只有一个waiting[i]被设置为false，以维护互斥要求。

#### 信号量

Process *Pi:* 

```assembly
semaphore mutex; //initially mutex = 1
do{
	wait(mutex);
    	critical section
 	signal(mutex);
    	remainder section
}while(1);
```

##### 定义

```assembly
wait(S):
	S.value--;
	if (S.value < 0) { 
		add this process to S.L;
        block;
	}
signal(S): 
	S.value++;
	if (S.value <= 0) {
		remove a process P from S.L;
        wakeup(P);
	}
```

死锁：两个或多个进程无限地等待一个事件，而该事件只能由这些等待进程之一来产生。

饥饿：无限阻塞。一个被悬挂的进程可能永远无法从信号量队列中移出。

##### 类型

* 计数信号量：其整数值可跨越于一个不受限制的域内。
* 二进制信号量：只能为整数值0或1

如何用二进制信号量实现计数信号量

```assembly
binary-semaphore S1=1, S2=0;
int C;  // initial value of semaphore S
```

*wait* operation

```assembly
wait(S1);
C--;
if (C < 0) { signal(S1);  wait(S2); }
signal(S1);
```

*signal* operation

```assembly
wait(S1);
C ++;
if (C <= 0) 	signal(S2);
else		signal(S1);
```

#### 同步的经典问题

##### 有限缓存问题

Shared Data

```assembly
mutex = 1, // To protect the buffer pool
full  = 0, // To count the number of full  buffers
empty = n; // To count the number of empty buffers
```

Producer Process

```assembly
while (1)	
{ …
	produce an item in nextp
	…
	wait(empty);

	wait(mutex);
	…; 	add nextp to buffer; …
	signal(mutex);

	signal(full);
}
```

Consumer Process

```assembly
while (1)
{ 	
	wait(full);

	wait(mutex);
	 …; remove one buffer to nextc;  …
	signal(mutex);

	signal(empty);
	…
	consume the item in nextc
	…
} 
```

##### 读者写者问题

一个数据对象可以为多个并发进程所共享。其中有的进程可能只需要读共享对象的内容，而其他进程可能要更新共享对象（即读和写）。

* 读者优先

  为了确保不会产生混乱，要求作者对共享对象有完全的访问。

  信号量wrt为读者和写者进程所共用，供写者作为互斥信号量使用。它为第一个进入临界区和最后一个离开临界区的读者所使用。

  信号量mutex用于确保在更新变量readcount时的互斥。

  变量readcount用来跟踪有多少进程正在读对象。

  Shared data

  ```assembly
  semaphore 
  	mutex = 1, 
  	wrt   = 1;
     	
  int readcount = 0;
  ```

  Writers process: 

  ```assembly
  wait(wrt);
      writing is performed
  signal(wrt);
  
  	remainder section 
  ```

  Readers process: 

  ```assembly
  wait(mutex);
  readcount++;	
  if (readcount == 1) wait(wrt);
  signal(mutex);
  	reading is performed
  wait(mutex);
  readcount--;
  if (readcount == 0) signal(wrt);
  signal(mutex):
  
  	remainder section
  ```

* 写者优先

##### 哲学家就餐问题

哲学家问题是需要在多个进程之间分配多个资源且不会出现死锁和饥饿形式的简单表示。

* Solution 1

  解决方法：每只筷子都用一个信号量来表示。一个哲学家对信号量执行wait操作试图夺取相应的筷子；他会通过对适当信号量执行signal操作以释放相应的筷子。

  ```assembly
  semaphore chopstick[5] 
   		= {1, 1, 1, 1, 1};
  		// One chopstick can be picked up by 
  		// one philosopher at a time
  do{
  	wait(chopstick[i])
  	wait(chopstick[(i+1) % 5])
  		 …
  		eat
  		 …
  	signal(chopstick[i]);
  	signal(chopstick[(i+1) % 5]);
  		 …
  		think
  		 …
  }while(1);
  ```

* Solution 2

  ```assembly
  semaphore chopstick[5] =
   			{1, 1, 1, 1, 1};
  		// One chopstick can only be picked up 
  		// by one philosopher
  
  		semaphore coord = 4;
  		// Only four philosophers can try to eat
  		// simultaneously 
  do{
  	wait(coord);
  	wait(chopstick[i])
  	wait(chopstick[(i+1) % 5])
  		 …eat …
  	signal(chopstick[i]);
  	signal(chopstick[(i+1) % 5]);
  	signal(coord);
  		 …think…
  }while(1);				
  ```

### 死锁

如果所申请的资源被其他等待进程占有，那么该等待进程可能再也无法改变其状态，这种情况称为死锁。

系统拥有一定数量的资源，分布在若干竞争进程之间。资源分成多种类型，如内存空间、CPU周期、文件、I/O设备等。每种类型有相同数量的实例。

正常操作模式下，进程按如下顺序使用资源：

* 申请：如果申请不能立即被允许，那么申请进程必须等待直到它获得该资源为止。
* 使用：进程对资源进行操作。

* 释放：进程释放资源。

开发多线程应用的程序必须特别关注死锁问题，因为多个线程可能因为**竞争共享资源**而容易产生死锁。

如果以下四个条件同时满足，那么就会引起死锁

* 互斥：至少有一个资源必须处于非共享模式；即一次只有一个进程使用。如果另一资源申请该资源，那么申请进程必须延迟直到该资源释放为止。
* 占有并等待：一个进程必须占有至少一个资源，并等待另一资源，而该资源为其他进程所占有。
* 非抢占：资源不能被抢占；即，只有进程完成其任务之后，才会释放其资源。
* 循环等待：有一组进程{P0, P1, …, Pn}，P0等待的资源为P1所占有，P1等待的资源为P2所占有，Pn-1等待的资源为Pn所占有，Pn等待的资源为P0所占有。

死锁问题可用称为**系统资源分配图**的**有向图**进行更为精确地描述。这种图由一个节点的集合V和一个边的集合E组成。节点集合V分成两种类型的节点P={P1,P2,…,Pn}(系统活动进程的集合)和R={R1,R2,…,Rm}(系统所有资源类型的集合)。

* 请求边：有向边 *P*i → *Rj*

* 分配边：有向边 *Rj* → *Pi*

如果图没有环，那么系统就没有进程死锁。如果图有环，那么可能存在死锁。

* 如果每种资源类型只有一个实例，则死锁
* 如果每种资源类型存在若干个实例，则只是有可能会发生死锁。

死锁处理方法

* 可使用协议以预防或避免死锁，确保系统永远不会进入死锁状态
* 可允许系统进入死锁状态，然后检测它，并加以恢复
* 可忽略这个问题，认为死锁不可能在系统内发生。

##### 死锁预防

只要死锁出现的四个必要条件之一不满足就可以。

* 互斥：对于非共享资源，必须要有互斥条件。共享资源不要求互斥访问。
* 占有并等待：为了确保占有并等待条件不会在系统内出现，必须保证——当一个进程申请一个资源时，它不能占有任何其他资源。
  * 一种方法是每个进程在执行前申请并获得所有资源。
  * 另一种方法是允许进程在没有资源时才可申请资源。

两种方法都有资源利用率低和可能发生饥饿的缺点。

* 非抢占：如果一个进程占有资源并申请另一个不能立即分配的资源，那么其现已分配的资源都被抢占。**通常应用于其状态可以保存和恢复的资源**，如CPU寄存器和内存空间，不能适用于其他资源如打印机和磁带驱动器。
* 循环等待：对所有资源进行完全排序，且要求每个进程按递增顺序来申请资源

对于死锁的互斥条件和不可抢占条件，由于它们是由**资源本身的独占性**所决定的，不允许进程同时共享和抢占，所以这两个条件不可能被破坏，因此只能从另两个必要条件入手，出现了静态资源分配法（避免占有并等待）和有序资源分配法（避免循环等待）。

##### 死锁避免

通过限制资源申请的方法来预防死锁的副作用是设备使用率低和系统吞吐率低。

假定有了关于每个进程的申请与释放的**完全顺序**，可决定进程是否因申请而等待。

每次申请要求系统考虑现有可用资源、现已分配给每个进程的资源和每个进程将来申请与释放的资源，以决定当前申请是否满足或必须等待从而避免死锁将来发生的可能性。

避免死锁的另一种方法要求有关如何申请资源的附加信息。最简单且有效的模型要求每个进程事先声明它**所需要的每种资源的最大数量**。

死锁避免算法动态检查资源分配状态，以保证不存在循环等待的条件。资源分配状态通过可用资源数量、已分配资源数量，及进程最大申请数量来定义

安全状态

当一个进程申请一个可用资源的时候，系统必须决定这次分配是否会使系统处在一种安全状态。如果存在所有进程的一种安全序列，则系统是安全的。

进程序列<P1, P2, …, Pn>，如果对于每个Pi，Pi申请的资源小于当前可用资源加上所有进程Pj（其中j < i）所占有的资源，那么这一顺序为安全序列。如果没有这样的序列存在，则系统状态就处于不安全。

##### 资源分配图算法

需求边－－用虚线表示

如果有一个资源分配系统，每种资源类型只有一个实例，那么资源分配图的变形可用于死锁避免。资源分配图算法要求**系统必须事先要求资源。**

##### 银行家算法

多实例

每个进程必须事先声明资源最大使用量，当一个进程申请资源时，有可能必须等待，进程得到所有资源后，它必须在某个确定的时间之后将资源返回给系统。

如果一个系统既不采用死锁预防算法也不采用死锁避免算法，那么可能会出现死锁。在这种环境下，系统应提供：

* 一个用来检查系统状态从而确定是否出现了死锁的算法。
* 一个用来从死锁状态中恢复的算法。

#### 死锁检测

等待图

从资源分配图中，删除所有资源类型节点，合并适当边，就可以得到等待图。

节点表示进程，Pi->Pj表示Pi等待Pj释放一个Pi所需的资源。

周期性地调用在图中进行搜索的算法，从图中检测环的算法需要n2级别操作，其中n为图中的节点数。

检测算法

Available：长度为m的向量，表示各种资源的可用实例

Allocation：n×m矩阵，表示当前各进程的**资源分配**情况

Request：n×m矩阵，表示当前各进程的**资源请求**情况。如果Request[i, j] = k, 那么*P*i现在需要k个资源*R*j

你可能不明白只要我们确定Requesti £ Work，就回收了进程Pi的资源。大家都知道Pi现在不参与死锁。因此，可以乐观地认为Pi不再需要更多资源以完成其任务；因此它会返回其现已分配的所有资源。如果假定不正确，那么死锁会稍后发生。下次调用死锁算法时，会检测到死锁状态。

应何时调用检测算法，取决于两个因素：

* 死锁可能发生的频率是多少？
* 当死锁发生时，有多少进程会受影响？

当某个进程提出请求且得不到满足时，才会出现死锁，这时可以调用死锁检测算法。但死锁后的每一个请求都会造成死锁。因此，可能需要对于之后的每个请求都调用死锁检测算法，但会引起相当的计算开销。

#### 死锁恢复

进程终止

资源抢占

人工处理死锁

让系统从死锁状态中自动恢复

打破死锁状态有两个方法

* 简单地终止一个或多个进程以打破循环等待
* 从一个或多个死锁进程那里抢占一个或多个资源

有两种方法通过终止进程以取消死锁

* 终止所有进程
* 一次只终止一个进程直到取消死锁循环为止

确定终止哪个进程或哪些进程可以打破死锁需要考虑的因素

* 进程的优先级是什么？
* 进程已计算了多久，进程在完成其指定任务之前还需要多久？
* 进程使用了多少什么类型的资源（是否容易抢占？）
* 进程需要多少资源以完成？
* 多少进程需要被终止？
* 进程是交互的还是批处理的？

如果要求使用抢占来处理死锁，那么有三个问题需要处理：

* 选择一个牺牲品

* 回滚：**必须将被抢占进程的状态恢复到某个安全状态**

* 饥饿：如何保证资源不会总是从同一个进程被抢占。

  解决方法：在代价因素中加上回滚次数。

### 内存管理

#### 背景

为了执行，程序应被调入内存并放在进程内。

* 逻辑地址：由CPU生成；也称为虚拟地址
* 物理地址：内存单元所看到的地址

在编译时和加载时的地址绑定方案中，逻辑地址与物理地址是相同的。但是，执行时的地址绑定方案导致不同的逻辑地址和物理地址。

关键点：加载之前已经形成绝对地址，逻辑地址的值已经等于绝对地址。

##### MMU内存管理单元

运行时从**虚拟地址**映射到**物理地址**的硬件设备称为**内存管理单元**

用户进程所生成的地址在送交内存之前，都将加上重定位寄存器的值。

用户程序处理的是逻辑地址，它永远不会看到真实的物理地址。

通常，将指令与数据捆绑到内存地址可以在以下步骤的任何一步中执行。

* 编译时：如果在编译时就知道进程将在内存中的驻留地址，那么就可以生成绝对代码。如果将来开始地址发生了变化，那么就必须重新编译代码。
* 加载时：如果在编译时并不知道进程将驻留在何处，那么编译器就必须生成可重定位代码。(例如：从本模块开始的第14字节)，对于这种情况，最后捆绑会延迟到加载时才进行。
* 运行时：如果进程在执行时可以从一个内存段移到另一个内存段，那么捆绑必须延迟到执行时才进行。采用这种方案需要特定硬件支持才行。

##### 动态加载

一个子程序只有在调用时才被加载

更好的内存空间利用率，不用的子程序不会被装入内存。

如果大多数代码需要用来处理异常情况，如错误处理，那么这种方法特别有用。

动态加载不需要操作系统提供特别的支持。利用这种方法来设计程序主要是**用户的责任**。不过，操作系统可以帮助程序员，如提供子程序库以实现动态加载。

##### 动态链接

链接过程推迟到执行时来进行。

存根是一小段代码，用来指出如何定位适当的内存驻留程序，或如果该程序不在内存时应如何装入库

存根会用子程序地址来替换自己，并开始执行子程序。

OS需要检查子程序是否在进程的内存地址空间内。

动态链接对于库来说是非常有用的。

##### 覆盖

为了能让进程比它所分配到的内存空间大，可以使用覆盖。

在任何时候只在内存中保留所需的指令和数据。当需要其他指令时，它们会装入到刚刚不再需要的指令所占用的内存空间内。

由用户来实现，不需要OS的特别支持。但用程序实现覆盖比较复杂。

考虑一个**two-pass汇编程序**。

Pass 1 70KB

Pass 2 80KB

Symbol table 20KB

Common routines 30KB

在第一遍时，建立**符号表**；在第二遍时，生成**机器码**。

可以定义两个覆盖：覆盖A是符号表、公共程序和第一遍代码；覆盖B是符号表、公共程序和第二遍代码。可以增加一个**覆盖驱动程序**（10KB）。

#### 交换

进程可以暂时从内存中交换出来到备份存储上，当需要再执行时再调回到内存中。

备份存储 － 通常是快速磁盘。这必须足够大，以便容纳所有用户的内存映象拷贝，它也必须提供对这些内存映象的直接访问。

滚进、滚出 － 是**交换策略**的一个变种，被用于基于优先权的调度算法中。如果一个更高优先级进程来了且需要服务，内存管理可以交换出低优先级的进程，以便可以装入和执行更高优先级的进程。当更高优先级进程执行完后，低优先级进程可以交换回内存以继续执行。

交换时间的主要部分是转移时间。总的转移时间与所交换的内存空间直接成正比。

交换的修改版本在许多系统中被采用。（如UNIX, Linux及Windows)

交换通常不执行，但当有许多进程运行且内存空间吃紧时，交换开始启动。如果系统负荷降低，那么交换就暂停。

#### 连续内存分配

内存通常分为两个区域：

* 一个用于驻留操作系统，常与中断向量一起放在低内存

* 另一个用于用户进程，常放在高内存。

##### 内存保护

为什么

* 保护操作系统不受用户进程所影响
* 保护用户进程不受其他用户进程所影响。

通过采用重定位寄存器和界限寄存器，可以实现对内存的保护。可以保证操作系统和其他用户程序及数据不受该进程的运行所影响。

重定位寄存器含有最小的物理地址值；界限寄存器含有逻辑地址值的范围。

有了重定位寄存器和界限寄存器，每个逻辑地址必须小于界限寄存器；MMU动态地将**逻辑地址加上重定位寄存器的值**后映射成物理地址。映射后的物理地址再送交给内存单元。

##### 内存分配

多分区分配

最为简单的内存分配方法之一就是将内存分为多个固定大小的分区。每个分区只能容纳一个进程。

操作系统有一个表用于记录哪些内存可用和哪些内存已用。通常，一组不同大小的孔分散在内存中。

当有新进程需要内存时，为该进程查找足够大的孔。如果找到，可以为该进程分配所需的内存，未分配的可以下次再用。如果孔太大，那么就分为两块：一块分配给新进程；另一块还回到孔集合。当进程终止时，它将释放其内存，该内存将还给孔集合。如果新孔与其它孔相邻，那么将这些孔合并成大孔。这时，系统可以检查是否有进程在等待内存空间，新合并的内存空间是否满足等待进程。

动态加载问题

从一组可用孔中选择一个空闲孔的最为常用方法有：

* 首次适应：分配第一个足够大的孔。
* 最佳适应：分配最小的足够孔。
* 最差适应：分配最大的孔。

模拟结果显示首次适应和最好适应在执行时间和利用空间方面都好于最差适应。首次适应和最好适应在利用空间方面难分伯仲，但是首次适应要快些。

##### 碎片

当所有总的内存之和可以满足请求，但并不连续时，就出现了外部碎片问题。

进程所分配的内存可能比所需要的要大。这两个数字之差称为内部碎片，这部分内存在分区内，而又不能用。

一种解决外部碎片问题的方法是紧缩。紧缩的目的是移动内存内容，以便所有空闲空间合并成一整块。紧缩是有一定条件的，要求重定位是动态的。

另一种可能解决外部碎片问题的方法是允许物理地址空间为非连续，这样只要有物理内存就可为进程分配。有两种互补的机制可以实现这种算法：分页机制和分段机制。这两种技术也可以组合到一起。

#### 分页

物理内存分为固定大小的块，称为**帧**。

逻辑内存也分为同样大小的块，称为**页**。

备份存储也可分为固定大小的块，其大小与内存的帧一样。

页大小（与帧大小一样）是由硬件来决定的。

CPU生成的地址分成以下两部分

**页号(p)**：页号作为页表中的索引。页表中包含每页所在物理内存的基地址。

**页偏移(d)**：与页的基地址组合就形成了物理地址，就可送交物理单元。

页的大小通常为2的幂，根据计算机结构的不同，其大小从512B到16MB字节不等。

选择2的幂作为页面大小可以很容易的把逻辑地址转换成页号和页偏移。

如果逻辑地址空间是2m，页面大小是2n（byte 或word），那么逻辑地址的高m – n 位是页号，低n 位是页偏移

采用分页技术不会产生外部碎片：每个帧都可以分配给需要它的进程。不过，分页有内部碎片。随着时间的推移，页的大小也随着进程、数据和内存的不断增大而增大。

If a frame is 4KB, then a system with 4-byte page-table entries can address 2<sup>44</sup> bytes of physical memory.

当系统需要执行一个进程时，它将检查该进程所需要的页数。因此，如果进程需要n页，那么内存中至少应有n个帧。如果有，那么就可分配给新进程。进程的第一页装入一个已分配的帧，帧号放入**进程的页表中**。下一页分配给另一帧，其帧号也放入进程的页表中。

页表的硬件实现有多种方法。

最为简单的一种方法是将页表作为一组**专用寄存器**来实现。CPU分派程序在装入其他寄存器时，也需要装入这些寄存器。

页表非常大的时候，采用快速寄存器来实现页表就不可行了。因而需要将页表放在内存中，并将页表基寄存器（PTBR）指向页表。改变页表只需改变这一寄存器即可，这也大大降低了切换时间。

关联内存 － 并行搜索

当关联内存根据给定值查找时，它会同时与所有键进行比较。如果找到条目，那么就得到相应的值域

地址转换（A’, A’’）

如果A’在关联寄存器中，则直接取出其对应的frame #，否则从内存中的页表当中得到frame #

查找的速度非常快；但是硬件昂贵。一个TLB 中往往包含很少的表项，数量通常在64 到1,024 之间。

当CPU产生逻辑地址后，其页号提交给TLB。如果找到页号，那么也就得到了帧号，并可用来访问内存。整个任务与不采用内存映射相比，其时间长度缩短了**10%**。

如果不能在TLB 中找到页号，那就必须访问内存中的页表。当获得帧号时，我们可以用它来访问内存。另外，我们把这个页号和帧号添加到TLB 中，这样在下一次引用时可以快速的找到它们。如果TLB 已经满了，那么操作系统必须要选择一个表项置换。置换策略有最近最少使用（LRU, least recently used）、随机策略等多种。

##### 有效访问时间nEffective Access Time (EAT)

$$
EAT = (1 + ε) α + (2 + ε)(1 – α) = 2 + ε – α
$$

##### 内存保护

在分页环境下，内存保护是通过与每个帧相关联的**保护位**来实现的。通常这些位保存在页表中，任何一位都能定义一个页是可读、可写或只可读。

有效无效位与页表中的每一条目相关联：

* 当该位有效时，该值表示相关的页在进程的逻辑地址空间内，因此是合法的页。
* 该位无效时，该值表示相关的页不在进程的逻辑地址空间内。

##### 页表结构

* 层次化分页

  绝大多数现代计算机系统支持大逻辑地址空间。在这种情况下，页表本身可以非常大。显然，人们并不愿意在内存中连续地分配这个页表。这个问题的一个简单解决是将页表划分成更小部分。

  完成上述划分有许多方法，一种方法是使用两层分页算法，就是将页表再分页。

* Hash页表

  处理超过32位地址空间的常用方法是使用Hash页表。

  虚拟地址中的虚拟页号被放入hash页表中。hash页表的每一条目都包括一个链接组的元素，这些元素hash成同一位置（碰撞）。

  虚拟页号与链表中的每 一个元素的第一个域相比较。如果匹配，那么对应的帧码就用来形成位置地址。如果不匹配，那么就对链表中的下一个域进行页码比较。

  每个元素有三个域：虚拟页码、所映射的帧号和指向链表中下一个元素的指针。

* 反向页表

##### 共享页

如果代码是重入的，那么它在执行时决不会改变自己。因此，两个或更多进程可以同时执行代码。

每个进程都有自己的寄存器拷贝和保存进程执行所需数据的数据存储拷贝。

#### 分段

分页内存管理中：用户观点的内存和实际内存分离。用户观点的内存需要映射到实际内存。

然而，用户并不会希望把内存看作一个线性字节数组。用户通常会愿意将内存看做为一组不同长度的段的集合，这些段之间并没有一定的顺序。

分段是支持**用户观点的内存管理方案**。

程序包含许多段。

* 每个段有名字。
* 每个段有不同的长度，段的长度由段在程序中的目的所决定。
* 段中的每一元素由它们相对段的开始的偏移量所标识。
* 各个段之间的顺序没有任何意义。

逻辑地址空间是由一组段组成。每个段都有名称和长度。地址指定了段名称和段内偏移。

逻辑地址由两个元素组成

<段号，偏移>

段表：将二维的用户定义地址映射为一维物理地址。段表的每个条目都有段基地址和段界限。

* 基地址：包含段的起始地址
* 界限：指定段的长度

段表基地址寄存器（STBR）指向内存中的段表的位置。

段表长度寄存器（STLR）指示程序所用的段的个数，段号S小于STLR的时候才是有效的

一个逻辑地址由两部分组成：段号s和段内的偏移d。

段号用做段表的索引。逻辑地址的偏移d应位于0和段界限之间。如果不是这样，则会陷入到操作系统中。如果偏移d合法，那么就与基地址相加而得到所需字节在物理内存的地址。因此段表是一组**基址和界限寄存器**对。

##### 优点

分段的一个显著优点是可以将段与对其的保护相关联。因为段内所有内容可能会按同样方式使用。因此有的段是指令，而有的段是数据。**内存映射硬件**会检查与段条目相关联的保护位以防止对内存的非法访问。

分段的另一个优点是关于代码或数据的共享。每个进程都有一个段表，当该进程被允许使用CPU时，**分派程序**会定义一个**硬件段表**。当两个进程的某些条目指向同一个物理位置时，就可以共享段。

代码段通常会包括对自己的引用。例如，条件转移有一个转移地址，该地址包括段号和偏移。转移地址的段号与代码段的段号一样。如果共享这个段，那么所有共享进程必须使得共享代码段有同样的段号。

例如，如果共享sqrt子程序，一个进程需要将它作为段4，而另一个进程需要将它作为17，那么sqrt子程序如何来引用自己呢？因为只有一个sqrt子程序的物理拷贝，**对于两个用户来说该子程序必须用同样方法来引用自己：它必须有一个唯一的段号。**随着共享段用户的增加，**寻找一个可以接受的段号**的难度会增加。

#### 段页

MULTICS采用带分页的分段方法来解决外部碎片的问题

与纯粹的分段式内存管理不同，段表的条目包含的不是段的基地址，而是该段的页表的基地址

### 虚拟内存

之前讨论的内存管理方法要求在进程执行之前必须将这个进程放入内存之中。

在许多情况下并不需要将整个程序放到内存中。例如：

* 程序通常有处理异常错误条件的代码。由于这些代码即使有也是很少发生，所以这些代码几乎不执行。
* 数组、链表和表通常分配了比实际所需要更多的内存。
* 程序的某些选项或特点可能很少使用。

即使在需要完整程序时，并不是同时需要所有的程序（例如，与覆盖相似的情况）。

能够执行只有部分在内存中的程序会有很多好处：

* 程序不再受现有的物理内存空间限制。简化了编程任务。
* 因为每个用户程序使用了更少的物理内存，所以更多的程序可以同时执行。
* 由于装入或交换每个用户程序到内存中所需的I/O会更少，**用户程序会运行的更快**。

虚拟内存管理是用于描述一种技术的术语，通过这种技术使计算机拥有比实际拥有的内存要大。

虚拟内存将内存抽象成一个巨大的、统一的存储数组，进而将用户看到的逻辑内存与物理内存分开。

* 只要部分需要的程序放在内存中就能使程序执行
* 逻辑地址空间可以比物理地址空间大。
* 允许地址空间被多个进程共享
* 允许更多进程被创建

#### 按需调页

请求页面调度类似于分页系统加上交换。**进程驻留在次级存储器上**。

当需要执行进程时，将它调入内存。不过，**不是将整个进程换入内存**，而是使用lazy swapper。lazy swapper只有在需要页时，才将它调入内存。

**由于将进程看作一系列的页**，而不是一个大的连续空间，因此使用“交换”从技术上来讲并不正确。交换程序对整个进程进行操作，而调页程序只是对进程的**单个页**进行操作。因此，在讨论有关请求页面调度时，需要使用调页程序而不是交换程序。

只在页面需要时，才把它们载入内存

* 需要更少的输入输出
* 更小的内存
* 更快的响应
* 更多的用户

对这种方案，需要一定形式的**硬件**来区分哪些页在**内存**里，哪些页在**磁盘**上。**有效-无效位**可以用于这一目的。

* 现在当该位置为“有效”时，该值表示相关的页既合法且也在内存中。
* 当该位设置为“无效”时，该值表示相关的页为**无效**（也就是，不在进程的逻辑地址空间中）或者**有效但在磁盘上**。

##### 页错误陷阱处理

* **检查**进程的**页表**，以确定该引用是**合法还是非法**的地址访问。
* 如果引用非法，那么终止进程。如果引用有效但是尚未调入页面，那么现在应调入。
* 找到一个空闲帧（从空闲帧链表中取一个）
* 调度一个磁盘操作，以便将**所需要的页**调入刚分配的帧
* 当磁盘读操作完成后，**修改进程的内部表和页表**，以表示该页已在内存中。
* **重新开始**因非法地址陷阱而中断的指令。进程现在能访问所需的页，就好像它似乎总在内存中。

##### 支持请求页面调度的硬件：

* 页表：该表能够通过有效-无效位或保护位的特定值，将条目设为无效。
* 次级存储器：该次级存储器用来保存不在内存中的页。次级存储器通常是快速磁盘。

##### 性能

从理论上说，有的程序的**单个指令可能访问多个页的内存**（一页用于指令，许多页用于数据），从而一个指令可能产生多个页错误。这种情况会产生令人无法接受的系统性能。

幸运的是，对运行程序的分析说明了这种情况是极为少见的。程序具有引用的局部性，这使得请求页面调度性能较为合理。

请求页面调度对计算机系统的性能有重要影响。

计算关于请求页面调度内存的有效访问时间：
$$
EAT = (1 – p)  (memory access) + p  (page fault time)
$$
p为页错误的概率

#### 进程创建

虚拟内存也能在进程创建时，提供其他好处：

* 写时拷贝

  写时拷贝允许父进程和子进程开始时共享同一页面。这些页面标记为写时复制，即如果任何一个进程需要对页进行写操作，那么就创建一个共享页的拷贝。

  采用写时拷贝技术，很显然只有被进程所修改的页才会复制，因此创建进程更有效率。

  写时拷贝时所需的空闲页来自一个空闲缓冲池。该缓冲池中的页在分配之前先填零，以清除以前的页内容。

* 内存映射文件

  内存映射文件I/O将文件I/O作为普通内存访问，它允许一部分虚拟内存与文件逻辑相关联。文件的内存映射可将一磁盘块映射成内存的一页。

  开始的文件访问按普通请求页式调度来进行，**会产生页面错误**。这样，一页大小的部分文件从文件系统读入物理页，**以后文件的读写**就按通常的内存访问来处理。通过内存的文件操作而不是使用系统调用read和write，简化了文件访问和使用。

  有的操作系统只能通过特定的系统调用提供内存映射，而通过标准的系统调用处理所有其他文件I/O。有的操作系统将所有文件I/O作为内存映射，以允许文件访问在内存中进行。

  多个进程可以允许将同一文件**映射到各自的虚拟内存中**，以允许数据共享。

#### 页面置换

随着增加多道程序的级别，**平均内存使用接近可用的物理内存时**，这种情况就可能发生。

用于I/O的缓冲也需要使用大量的内存，这种使用会增加内存布置算法的压力。确定多少内存用于分配给I/O而多少内存分配给程序页面是一个棘手问题。

有的系统为I/O缓冲分配了一定比例的内存，而其他系统允许用户进程和I/O子系统竞争使用所有系统内存。

过渡分配会导致页错误。

当一个用户进程执行时，会出现页错误。**硬件陷入到操作系统**。接着操作系统会检查其**内部表**以确定该页错误是合法还是非法的内存访问。进而操作系统会确定所需页在磁盘上的位置，但是却发现空闲帧列表上**并没有空闲帧**：所有帧都在使用。这时操作系统会有若干选择：

* 它可以终止用户进程。
* 操作系统也可以交换出一个进程，以释放其所有帧，并降低多道程序的级别。
* 操作系统可以执行页置换。

修改页错误处理程序以包括页置换：

* 查找所需页在磁盘上的位置
* 查找一空闲帧
  * 如果有空闲帧，那么就使用它
  * 如果没有空闲帧，那么就使用页置换算法以选择一个“牺牲”帧（victim frame）。
  * 将“牺牲”帧的内容写到磁盘上；改变页表和帧表。

* 将所需页读入（新）空闲帧；改变页表和帧表
* 重启用户进程。

使用页置换，页错误处理时间加倍。

可通过修改位（或脏位）来降低额外开销。每页或帧可以有一个修改位通过硬件与之相关联。每当页内的任何字或字节被写入时，硬件就会设置该页的修改位以表示该页以修改。

如何选择一个置换算法？通常采用最小页错误率的算法。

可以这样来评估一个算法：针对特定内存引用串运行某个置换算法，并计算出页错误的数量。内存的引用序列称为**引用串**。

通常，人们期待随着帧数量增加，那么页错误数量会降低至最小值。当然，增加物理内存就会增加帧的数量。

##### 算法

**FIFIO**

为了说明与FIFO页置换算法相关的可能问题。考虑如下引用串：1，2，3，4，1，2，5，1，2，3，4，5。上图显示页错误对现有帧数的曲线。注意到对4帧的错误数（10）比对3帧的错误数（9）还要大。这种最为令人难以置信的结果称为Belady异常：**对有的页置换算法，页错误率可能会随着所分配的帧数的增加而增加。**

**OPT最优页置换算法**

最优页置换算法是所有算法中产生页错误率最低的，且决没有Belady异常的问题。

置换那些在最长时间中不会被使用的页。

最优页置换算法难于实现，因为**需要引用串的未来知识**。

最优算法主要用于比较研究。例如，如果知道一个算法不是最优，但是与最优相比最坏不差于12.3％，平均不差于**4.7％，**那么也是很有用的。

**LRU最近最少使用算法**

LRU置换为每个页关联该页上次使用的时间。

当必须置换一页时，LRU选择最长时间没有使用的页。

实现

* 计数器

  为每个页表项关联一个使用时间域，并为CPU增加一个逻辑时钟或计数器。**对每次内存引用，计数器都会增加。**每次内存引用时，时钟寄存器的内容会复制到相应页所对应页表项的使用时间域内。置换具有最小时间的页。

* 页码堆栈

  每次引用一个页，该页就从堆栈中删除并放在顶部。这样，堆栈顶部总是最近使用的页，堆栈底部总是LRU页。

**近似页置换算法**

许多系统通过引用位方式提供一定的支持。页表内的每项都关联着一个引用位。每当引用一个页时，相应页的引用位就被硬件置位（置为1）。

* 附加引用位算法

  可以为位于内存中的每个表中的页保留一个8bit的字节。

  在规定的时间间隔（如，每100ms）内，时钟定时器产生中断并将控制转交给操作系统。操作系统把每个页的引用位转移到其8bit字节的高位，而将其他位向右移，并抛弃最低位。这些8bit移位寄存器包含着该页在最近8个周期内的使用情况。

  如果将这8bit字节作为无符号整数，那么具有最小值的页为LRU页，且可以被置换。例如，具有值为11000100的移位寄存器的页要比值为01110111的页更为最近使用。

* 二次机会算法

  当要选择一个页时，检查其引用位。

  如果其值为0那么就直接置换该页。

  如果该引用位为1,那么就给该页第二次机会，并选择下一个FIFO页。当一个页获得第二次机会时，其引用位清零，且其到达时间设为当前时间。

  一种实现二次机会算法的方法是采用循环队列。

* 增强型二次机会算法

**基于计数的页置换**

为每个页保留一个用于记录其引用次数的计数器。

最不经常使用页置换算法（least frequently used page replacement algorithm, LFU）要求置换计数最小的页。

最常使用页置换算法（most frequently used page-replacement algorithm, MFU）：具有最小次数的页可能刚刚调进来，且还没有使用。

#### 帧分配

每个进程帧的最小数量是由体系结构来定义的，而最大数量是由可用物理内存的数量来定义的。

在这两者之间，关于帧分配还是有很多选择的。

##### 分配算法

平均分配：如100帧，5个进程，则给每个进程20帧

比例分配：根据进程的大小按比例分配

特点：

每个进程所分配的数量会随着多道程序的级别而有所变化。如果多道程序程度增加，那么每个进程会失去一些帧以提供给新来进程使用。反之，原来分配给离开进程的帧可以分配给剩余进程

对于平均或比例分配，高优先级进程与低优先级进程一样处理。

另一个方法是使用比例分配的策略，但不是根据进程相对大小，而是根据进程优先级或是大小和优先级的组合。

如果进程 *P*i 产生了一个页错误，那么

* 从自身的帧中选择用于替换
* 从比自身优先级低的进程中选取帧用于替换

**全局置换**

允许一个进程从所有帧集合中选择一个置换帧，而不管该帧是否已分配给其他进程；一个进程可以从另一个进程中取帧。

**局部置换**

要求每个进程仅从其自己的分配帧中进行选择

采用局部置换策略，分配给每个进程的帧的数量不变。采用全局置换，一个进程可能从分配给其他进程的帧中选择一个进行置换，因此增加了所分配的帧的数量。

全局置换算法的一个问题是进程不能控制其页错误率。**一个进程的位于内存的页集合**不但取决于进程本身的调页行为，还取决于其他进程的调页行为。

采用局部置换算法，进程内存中的页只受该进程本身的调页行为所影响。

全局置换通常会有更好的系统吞吐量，且更为常用。

#### 颠簸

如果一个进程出现了页错误，必须置换某个页。然而，其所有页都在使用，它置换一个页，但又立刻再次需要这个页。因此，它会不断地产生页错误。进程继续页错误，置换一个页而该页又立即出错且需要立即调进来。

这种**频繁的页调度的行为**称做颠簸。如果一个进程在换页上用的时间要多于执行时间，那么这个进程就在颠簸。

CPU调度程序发现CPU利用率降低，因此会增加多道程序的程度。新进程试图从其他运行进程中拿帧，从而引起更多页错误，更长的调页设备的队列。因此，CPU利用率进一步降低，**CPU调度程序**试图再增加程序的程度。这样系统颠簸就出现了，**系统吞吐量突降，页错误显著增加**。因此，有效访问时间增加。最终因为进程主要忙于调页，系统不能完成一件工作。

局部模型说明，当进程执行时，它从一个局部移向另一个局部。

**局部是一个经常使用页的集合**。

一个程序通常由多个不同局部组成，它们可能重叠。如果进程有足够的帧包含它的所有局部，它会运行的很顺利。

为每个进程分配可以满足其当前局部的帧。该进程在其局部内会出现页错误，直到所有页在内存中；接着它不再会出现页错误直到它改变局部为止。

如果分配的帧数少于现有局部的大小，那么进程会颠簸，这是因为它不能将所有将经常使用的页放在内存中。

##### 工作集模型

**工作集窗口**（Working set window）：最近Δ个页面引用

最近Δ个引用的页集合称为**工作集合**（Working set）

如果一个页正在使用中，那么它就在工作集合内。如果它不再使用，那么它会在其上次引用的Δ时间单位后从工作集合中删除。

工作集合是程序局部的近似。

工作集合精度与Δ的选择有关。如果Δ太小，那么它不能包含整个局部；

* 如果Δ太大，那么它可能包含多个局部。
* 如果Δ为无穷大，那么工作集合是进程执行所碰到的所有页的集合。

##### 页错误频率策略

工作集合模型是成功的，工作集合模型知识能用于预先调页，但是用于控制颠簸有点不太灵活。一种更为直接的方法是采用页错误率策略。

建立可接受的页错误率

* 如果错误率太低，则进程可能有太多的帧，因此应丢弃一些帧
* 如果错误率太高，则为进程分配更多帧

与工作集合策略一样，也可能必须暂停一个进程。如果页错误增加且没有可用帧，那么必须选择一个进程暂停。接着，可将释放的帧分配给那些具有高页错误率的进程。

### 文件系统接口

#### 介绍

操作系统对**存储设备**的各种属性加以抽象并且定义了**逻辑存储单元（文件）**，再将文件映射到物理设备上。

**文件是记录在外存上相关信息的具有名称的集合。**从用户角度而言，文件是**逻辑外存**的最小分配单元，即数据除非在文件中，否则不能写到外存。

通常文件表示程序（源形式和目标形式）和数据。

* 数据文件
  * 数字的
  * 字符的
  * 二进制的

* 程序文件
  * 源程序
  * 目标程序
  * 可执行程序

文件属性

* 名称：文件符号名称是唯一的，按照人们容易读取的形式保存。有些OS区分大小写（如Linux，Unix），有些不区分（如DOS, Windows）。
* 标识符：标识文件系统内文件的唯一标签，通常为数字；这是文件的对人而言不可读的名称。
* 类型：由OS和程序定义。
* 位置：该信息指向设备和设备上文件位置的指针。
* 大小：文件当前大小，该属性也能包括可允许大小的最大值。
* 保护：决定谁能读、写、执行等的访问控制信息
* 时间、日期和用户标识：文件创建、上次修改和上次访问都可能有该信息。用于保护、安全和使用跟踪。

**文件的信息被保存在目录结构中，而目录结构也保存在外存上**

##### 文件结构

每个应用程序必须有自己的代码对输入文件进行**合适的解释**。**但所有的OS必须至少支持一种文件结构**，即**可执行文件结构**，以便能装入和运行程序。

* 无：字或字节的序列
* 简单记录结构
  * 行
  * 固定长度
  * 可变长度

* 复杂结构
  * 格式化文档
  * 可重定位装载文件

可通过在第一种表示方法中插入适当的**控制字符**来模拟后两种表示方法。

文件的结构由以下两者来决定

* OS
* 程序

结构太少会使编程不够灵活，然而结构太多会使操作系统过大且会使程序混淆。

##### 文件操作

创建文件

* 在文件系统中为文件找到空间
* 在目录中为新文件创建一个条目

写文件/读文件

在文件内重定位

截短文件（truncate）：只删除文件内容而保留其属性，而不是强制用户删除文件再创建文件。

删除文件：在目录中搜索给定名称的文件，找到相关目录条目后，释放所有的文件空间以便其他文件使用，并删除相应目录条目。

Open(Fi)：在磁盘上的目录结构中查找Fi，并将其内容复制到内存

Close(Fi)：将内存中的Fi的内容复制到位于磁盘上的目录结构中

**打开文件表**

以上所述的绝大多数文件操作都涉及到为给定文件搜索相关目录条目。为了避免这种不断的搜索操作，许多系统要求在首次使用文件时，使用系统调用open。操作系统维护一个包含所有打开文件的信息的表（打开文件表，open-file table）。当需要一个文件操作时，可通过该表的一个索引指定文件，而不是搜索。当不需要文件时，进程可以关闭它，操作系统从打开文件表中删除这一条目。

对于多用户环境如UNIX，操作系统open和close的实现更加复杂。在这些系统中，多个用户可能同时打开一个文件。通常，操作系统采用两级内部表：单个进程的表和整个系统的表。单个进程表跟踪单个进程打开的所有文件。表内所存是该进程所使用的文件的信息。例如，每个文件的当前文件指针就保存在这里，以表示下一个read或write调用所影响的文件位置。另外，还包括文件访问权限和记账信息。

单个进程表的每一条目相应地指向整个系统的打开文件表。

整个系统表包含进程无关信息如文件在磁盘上的位置、访问日期和文件大小。一旦一个进程打开一个文件，另一个进程执行open，其结果只不过简单地在其进程打开表中增加一个条目，并指向整个系统表的相应条目。通常，系统打开文件表的每个文件还有一个文件打开计数器open count，以记录多少进程打开了该文件。

#### 文件访问

最为简单的访问方式是顺序访问。文件信息按顺序，一个记录接着一个记录地加以处理。顺序访问基于文件的磁带模型。

另一方式是直接访问。文件由固定长度的逻辑记录组成，以允许程序按任意顺序进行快速读和写。直接访问方式是基于文件的**磁盘模型**，磁盘允许对任意文件块进行**随机读和写**。

直接访问文件可立即访问大量信息，数据库通常使用这种类型的文件。

可以用直接访问来模拟顺序访问，而用顺序访问模拟直接访问则是极为低效和笨重的。

其他访问方式可建立在直接访问方式之上。这些访问通常涉及创建文件索引。索引，如同书的索引，包括各块的指针。为了查找文件中的记录，首先搜索索引，再根据指针直接访问文件，以查找所需要的记录。

对于大文件，索引本身可能太大以至于不能保存在内存中。解决方法之一是为索引文件再创建索引。初级索引文件包括二级索引文件的指针，而二级索引再包括真正指向数据项的指针。

#### 目录结构

计算机的文件系统可以非常大。有的系统在数千吉磁盘上保存了数以万计的文件。为了管理所有这些数据，需要组织它们。这种组织通常分为两部分：

第一，磁盘分为一个或多个分区，或称为小型磁盘或卷。通常，每个系统磁盘至少包括一个分区，这是用来保存文件和目录低层结构。

第二，每个分区都包括了存储在分区中的文件的信息。这种信息保存在设备目录或卷内容表中。设备目录记录分区上所有文件的各种信息，如名称、位置、大小和类型等。

目录操作如下：

* 搜索文件
* 创建文件
* 列出目录
* 重命名文件
* 遍历文件系统。

**标准**

有效：迅速定位文件

命名：方便用户

* 两个不同的用户的文件名称可以相同

* 同一文件可以有不同的名称

分组：按文件的属性逻辑分组（如所有java程序，所有游戏等）

##### 结构

**单层**

所有文件都包含在同一目录中，便于支持和理解。但存在命名问题与分组问题。

**双层**

为不同的用户建立不同的目录（用户文件目录、主文件目录）

不同用户的文件允许同名

方便查找

不支持分组

**树状**

有效搜索

分组：允许用户定义其自己的子目录结构可以使其按一定结构组织文件。这种结构可以是按不同主题来组织文件；或按不同信息类型来组织文件。

当前目录（工作目录）

绝对路径与相对路径名

创建文件与目录通常在当前目录中进行

删除文件

**无环图**

无环图允许目录含有共享子目录和文件。同一文件或子目录可出现在两个不同目录中。**无环图是树形结构目录方案的自然扩展**。

无环图结构目录比树型结构目录更加灵活，但是也更为复杂。现在一个文件可有多个绝对路径名。这样，不同文件名可能表示同一文件。如果试图遍历整个文件系统，如查找文件，计算所有文件的统计数，复制所有文件到备份存储，可能会带来一定的问题。

另一问题是删除问题：一种可能是每当用户删除文件时就删除文件，但是这样会留下悬挂指针指向不再存在的文件。删除的另一种方法是保留文件直到删除其所有引用为止。

**通用图目录**

采用无环图结构的一个特别重要的问题是要确保没有环。如果从两层目录开始，并允许用户创建子目录，那么就产生了树结构目录。可以容易地看出对已存在的树结构目录简单地增加新文件和子目录将会保持树结构性质。然而，当对以存在的树结构目录增加链接时，树结构就破坏了，产生了**简单的图结构**。

#### 文件系统挂载

文件系统在访问之前必须已安装好。

尚未安装的文件系统必须安装到安装点上。

#### 文件共享

期望多用户系统上文件的共享

共享可以通过保护机制来实现

在分布式系统上，文件可以跨网络共享。NFS是一种常见的分布式文件共享方法

为了便于管理客户机－服务器服务，分布式信息系统，也称为分布式命名服务，用来提供用于远程计算所需的信息的统一访问。

域名系统（DNS）为整个因特网提供了主机名称到网络地址的转换。

其他分布式信息系统为分布应用提供了用户名称/口令/用户ID/组ID。

Sun Microsystem引入了黄页（NIS），绝大多数业界都采用了它，它将用户名、主机名、打印机信息等加以集中管理。

##### 一致性语义

描述了多用户同时访问共享文件的语义。

特别地，这些语义规定了一个用户所修改的数据何时对另一个用户可见。

UNIX语义

* 一个用户对已经打开的文件进行写操作，可以被同时打开同一文件的其他用户看见。
* 有一种共享模式允许用户共享文件当前指针的位置。

ASF语义

* 一个用户对打开文件的写不能被同时打开同一文件的其他用户所看见。
* 一旦文件关闭，对其修改只能为以后打开的会话所看见。已经打开文件的用户并不能看见这些修改。

永久共享文件语义

一旦一个文件被其创建者声明为共享，它就不能被修改。

永久共享文件有两个重要特性：文件名不能重用，且文件内容不可修改。

#### 文件保护

用户类型

* 拥有者
* 组
* 其他

### 文件系统实现

#### 文件系统结构

磁盘提供大量的外存空间来维持文件系统，磁盘的两个特点，使其成为存储多个文件的方便媒介

* **可以原地重写**；可以从磁盘上读一块，修改该块，并将它写回到原来的位置
* **可以直接访问磁盘上的任意一块信息**。（随机或顺序方式）

为了改善I/O效率，内存与磁盘之间的I/O转移是**以块为单位**而不是以字节为单位来进行的。

为了提供对磁盘的高效且便捷的访问，操作系统通过**文件系统**来轻松地存储、定位、提取数据。

文件系统的两个设计问题

* 如何定义文件系统对用户的接口

* 创建数据结构和算法来将逻辑文件系统映射到物理外存设备上

##### 分层

应用程序

**逻辑文件系统**

管理元数据。元数据包括文件系统的所有**结构数据**，而不包括实际数据（或文件内容）。

根据给定**符号文件名**来管理目录结构，并提供给文件组织模块所需要的信息。

逻辑文件系统通过文件控制块来维护文件结构。

* 文件控制块包含文件的信息，如拥有者、许可、文件内容的位置。
* 文件系统也负责保护和安全。

**文件组织模块**

知道文件及其逻辑块和物理块，可以将逻辑块地址转换成基本文件系统所用的物理块地址。

* 每个文件的逻辑块按从0或1到N来编码
* 每个文件的物理块地址是不同的，在分区内是唯一的。

空闲空间管理器

用来跟踪未分配的块并根据要求提供给文件组织模块。

**基本文件系统**	

向合适的设备驱动程序发送一般命令就可对磁盘上的物理块进行读写。

每个块由其磁盘地址来标识。

**I/O控制**

由**设备驱动程序**和**中断处理程序**组成，实现内存与磁盘之间的信息转移

输出：其输出由底层的、硬件特定的命令组成，这些命令用于硬件控制器，通过硬件控制器可以使**I/O设备与系统其他设备相连**。

设备驱动程序通常在I/O控制器的特定位置写入特定位格式来通知控制器在什么位置采取什么动作。

设备

绝大多数操作系统都只持多个文件系统。

#### 文件系统实现

实现文件系统要使用多个磁盘和内存结构。虽然这些结构因操作系统和文件系统而异，但是还是有一些通用规律的。

在磁盘上，文件系统可能包括如下信息：

* 如何启动所存储的操作系统
* 总的块数
* 空闲块的数目和位置
* 目录结构
* 各个具体文件等。

磁盘结构包括

* 引导控制块（boot control block）：包括系统从该分区引导操作系统所需的信息。通常为分区的第一块。如果该分区没有OS，则为空。（其他名称：引导块（Linux）、分区引导扇区（WindowsNT））
* 分区控制块（partition control block）：包括分区详细信息，如分区的块数、块的大小、空闲块的数量和指针、空闲FCB的数量和指针等（亦称为超级块（Linux）、主控文件表（WindowsNT））
* 目录结构：用来组织文件
* 文件控制块（FCB）：包括很多文件信息，如文件许可、拥有者、大小和数据块的位置等。UFS称之为索引节点。NTFS将这些信息存在主控制文件表中，主控文件采用关系数据库结构，每个文件占一行。

内存信息用于文件系统管理和通过缓存来提高性能。这些结构包括：

* 内存分区表：包含所有安装分区的信息
* 内存目录结构：保存近来访问过的目录信息（对安装分区的目录，可以包括一个指向分区表的指针）
* 系统范围的打开文件表：包括每个打开文件的FCB拷贝和其他信息
* 单个进程的打开文件表：包括一个指向系统范围内已打开文件表中合适条目的指针和其他信息
  * 文件描述符（file descriptor, Linux/UNIX）
  * 文件句柄（file handle, Windows）

为了**创建**一个新文件，应用程序调用逻辑文件系统。

* 分配一个新的FCB
* 把相应目录读入内存，
* 增加一个新的目录项
* 用新的文件名更新该目录和FCB
* 将结果写回到磁盘。

一旦文件被**创建**，它就能用于I/O。不过，首先应打开文件。

* 调用open将文件名传给文件系统。
* 当文件打开时，根据给定文件名来搜索目录结构。
* 将文件的FCB读入内存
* 其FCB复制到系统范围的打开文件表
* 在单个进程的打开文件表中会增加一个条目，并通过指针将系统范围的打开文件表的条目同其他域相连。
* 调用open返回一个指向单个进程的打开文件表中合适条目的指针。

关闭文件

* 删除一个相应的单个进程打开文件表的条目，
* 系统范围内打开文件表的打开数也会递减。
* 当打开文件的所有用户都关闭一个文件时，更新的文件信息会复制到磁盘的目录结构中，系统范围的打开文件表的条目也将删除。

有的系统更加复杂，它们将文件系统作为对其他系统方面的访问接口，如网络。

使用caches可以加速文件操作，BSD UNIX系统在使用缓存方面比较经典。

##### 虚拟文件系统

使用VFS（VFS使用面向对象技术来简化、组织和模块化实现过程）

采用数据结构和子程序，可以分开基本系统调用的功能和实现细节。因此，文件系统实现包括三个主要层次。

* 顶层：文件系统接口

  包括open、read、write和close调用及文件描述符。

* 中间层：虚拟文件系统

  VFS层通过定义一个清晰的VFS接口，以将文件系统通用操作和具体实现分开

  VFS是基于称为vnode的文件表示结构，该结构包括一个数值指定者以表示位于整个网络范围内的唯一文件。

* 底层：

  不同文件系统的实现

  * Ext3
  * Nfs

VFS区分本地文件和远程文件，根据文件系统类型可以进一步区分不同本地文件。

#### 目录实现

**线性表**

线性列表目录实现方法是使用存储文件名和数据块指针的线性列表。

**哈希表**

采用这种方法，除了使用线性列表存储目录条目外，还使用了哈希数据结构。它可以大大地降低目录搜索时间。

每个哈希条目可以是链表而不是单个值，可以采用向链表增加一项来解决冲突。

#### 分配方法

如何为多个文件分配磁盘空间，以便有效地使用磁盘空间和快速地访问文件。常用的磁盘空间分配方法有三个：

**连续**

每个文件占据磁盘上的一组连续的块

特点：

* 简单 － 只需要记录文件的起始位置（块号）及长度。
* 访问文件很容易，所需的寻道时间也最少

存在的问题

* 为新文件找空间比较困难（类似于内存分配中的连续内存分配方式）
* 文件很难增长

许多新的文件系统采用一种修正的连续分配方法

该方法开始分配一块连续空间，当空间不够时，另一块被称为扩展的连续空间会添加到原来的分配中。文件块的位置就成为开始地址、块数、加上一个指向下一扩展的指针。

**链接**

每个文件是磁盘块的链表；磁盘块分布在磁盘的任何地方

优点：

* 简单 － 只需起始位置
* 文件创建与增长容易

缺点：

* 不能随机访问
* 块与块之间的链接指针需要占用空间
  * 簇：将多个连续块组成簇，磁盘以簇为单位进行分配

* 存在可靠性问题

每个分区的开始部分用于存储该FAT表。每个磁盘块在该表中有一项，该表可以通过**块号**来索引。

目录条目中含有文件首块的块号码。根据块号码索引的FAT条目包含文件下一块的号码。这种链会一直继续到最后一块，该块对应FAT条目的值为**文件结束值**。未使用的块用0值来表示。

为文件分配一个新的块只要简单地找到**第一个值为０的FAT条目**，用新块的地址替换前面文件结束值，用文件结束值替代0。

**如果不对FAT采用缓存，FAT分配方案可能导致大量的磁头寻道时间。但通过读入FAT信息，磁盘能找到任何块的位置，从而实现随机访问。**

**索引**

将所有的数据块指针集中到索引块中，索引块中的第i个条目指向文件的第i块。

目录条目包括索引块的地址。

#### 空闲空间管理

为了记录空闲磁盘空间，系统需要维护一个空闲空间链表。空闲空间链表记录了所有空闲磁盘空间，即未分配给文件或目录的空间。当创建文件时，搜索空闲空间链表以得到所需要的空间，并分配给新文件。这些空间会从空闲空间链表中删除。

**位向量**

通常，空闲空间表实现为位图或位向量。每块用一位表示。

* 如果一块为空闲，那么其位为1；
* 如果一块已分配，那么其位为0。

当要查找第一空闲块，Macintosh操作系统会按顺序检查位图的每个字以检查其是否为0，再对第一个值为非0的字进行搜索值为1的偏移，该偏移对应着第一个空闲块。该块号码的计算如下：
$$
（一个字的位数）x（值为0的字数）+第一个值为1的位的偏移
$$
**链表**

链表(空闲链表)：将所有空闲磁盘块用链表连接起来，并将指向第一空闲块的指针保存在磁盘的特殊位置，同时也缓存在内存中。

* 不易得到连续空间
* 没有空间浪费

**组**

将n个空闲块的地址存在第一个空闲块中。这些块中的前n-1个确实为空。而最后一块包含另外n个空闲块的地址，如此继续。

**计数**

通常，有多个连续块需要同时分配或释放。因此，可以记录第一块的地址和紧跟第一块的连续的空闲块的数量n。这样，**空闲空间表**的每个条目包括磁盘地址和数量。

#### 恢复

一致性检查 － 比较目录中的数据与磁盘中的数据块，以消除不一致性

使用系统程序将数据从磁盘备份到其他存储设备（如磁盘，磁带）

* 增量备份
* 从备份上恢复数据以恢复丢失的文件或磁盘

### I/O系统

**对与计算机相连设备的控制是操作系统设计者的主要任务之一。**因为I/O设备在其**功能与速度**方面存在很大差异，所以需要采用多种方法来控制设备。这些方法形成了**I/O****子系统**的核心，该子系统使内核其他部分不必涉及复杂的I/O设备的管理。

I/O设备技术呈现两个相矛盾的趋势：

* 软硬件接口日益增长的标准化。
* I/O设备日益增长的多样性。

为了隐藏不同设备的细节和特点，操作系统内核设计成使用设备驱动程序模块的结构。

设备驱动程序为I/O子系统提供了统一接口，正如系统调用为应用程序与操作系统之间提供了统一的标准接口。

#### I/O硬件

##### 介绍

I/O设备具有无法想象的多样性

存储设备（磁盘、磁带）

传输设备（网卡、Modem）

人机交互设备（显示器、键盘、鼠标）

尽管I/O设备存在令人难以置信的差异，但只需要通过少数**几个概念**就可以理解**如何连上设备**和**如何用软件来控制硬件**。

公共概念

* 端口
* 总线：是一组线和一组严格定义的可以描述在线上传输信息的协议。
* 控制器：用于操作端口、总线或设备的一组电子器件

控制器有一个或多个用于数据和控制信号的寄存器。处理器通过读写这些寄存器的位组合来与控制器通信。

设备控制寄存器映射到处理器的地址空间。处理器执行I/O请求是通过标准数据传输指令来完成对设备控制器的读写。

**控制寄存器**

状态寄存器包含一些主机可读取的位信息。这些信息指示各种状态如当前任务是否完成，数据输入寄存器中是否有数据可以读取，是否出现设备故障等。

控制寄存器可以被主机用来向设备发送命令或改变设备状态。例如，串口控制寄存器中的一位选择全工通信或单工通信，另一位控制是否奇偶校验检查，第三位设置字长为7位或8位。

##### 轮询

假定有两个位来协调控制器与主机之间的生产者与消费者的关系。

1.**主机不断地读取忙位，直到该位被清除** (这个过程称为轮询，亦称忙等待-busy waiting)

2.主机设置命令寄存器中的**写**位并向数据输出寄存器中写入一个字节。

3.主机设置命令**就绪**位

4.当控制器注意到命令**就绪**位已被设置，则设置**忙**位。

5.控制器读取命令寄存器，并看到写入命令。它从数据输出寄存器中读取一个字节，并向设备执行I/O操作。

6.控制器清除命令**就绪**位，清除状态寄存器的**故障**位以表示设备I/O成功，清除**忙**位以表示完成。

##### 中断

CPU硬件有一条中断请求线（interrupt-request line, IRL），由I/O设备触发

设备控制器通过中断请求线发送信号而引起中断，CPU捕获中断并派遣到中断处理程序，中断处理程序通过处理设备来清除中断。

两种中断请求

* 非屏蔽中断：主要用来处理如不可恢复内存错误等事件
* 可屏蔽中断：由CPU在执行关键的不可中断的指令序列前加以屏蔽

##### DMA直接内存访问

对于需要大量传输的设备，例如磁盘驱动器，如果使用昂贵的通用处理器来观察状态位并按字节来向控制器送入数据（Programming I/O，PIO），那么就浪费了。

许多计算机为了避免用PIO而增加CPU的负担，将一部分任务下放给一个专用处理器，这称为DMA（direct-memory access）控制器。

在开始DMA传输时，主机向内存中写入**DMA命令块**。该块包括传输的源地址指针、传输的目的地址指针、传输的字节数。CPU在将该命令块**的地址写入到DMA控制器中后**，就继续其他工作。DMA控制器则继续去直接操作内存总线，无需主CPU的帮助即可以将地址放到总线以开始传输。

**DMA控制器与设备控制器之间的握手通过一对称为DMA-request和DMA-acknowledge的线来进行**。当有数据需要传输时，设备控制器就通过DMA-request线发送信号。该信号会导致DMA控制器抓住内存总线，并在内存总线上放上所需地址，并通过DMA-acknowledge线发送信号。当设备控制器收到DMA-acknowledge信号时，就可以向内存传输数据，并清除DMA-request请求信号。

1.设备驱动器被告知传递磁盘数据到地址为X处的缓冲区

2.设备驱动器告诉磁盘控制器传递从磁盘的C个字节到地址为X的缓冲区。

3.磁盘控制器初始化DMA传输

4.磁盘控制器向DMA控制器发送每个字节

5.DMA控制器向缓冲区X传输字节，增加内存地址并减少C直到C=0

6.当C=0时，DMA中断CPU，通知传输完毕

#### I/O API

I/O系统调用通用类型包装了设备行为，为应用程序隐藏了硬件差异。

设备驱动程序层的作用是为内核I/O子系统隐藏设备控制器之间的差异。

设备在许多方面都有很大差异：

**字符流或块**：字符流设备按一个字节一个字节地传输，而块设备以块为单位进行传输

**顺序或随机访问**：顺序设备按其故有的固定顺序来传输数据，而随机访问设备的用户可以让设备寻找到任一数据存储位置。

**同步或异步**：同步设备按一定响应时间来进行数据传输，而异步设备呈现的是无规则或不可预测的响应时间

**共享或专用**：共享设备可以被多个进程或线程并发使用，而专用设备则不能。

**操作速度**：设备速度从每秒几个字节到每秒数吉字节

**读写、只读、只写**：有的设备能读能写，而其他的只支持单向数据操作

解决方案是操作系统隐藏这些区别，提供几种设备访问类型。

##### 块与字符设备

* 块设备包括磁盘驱动器

  read，write，seek描述了块存储设备的基本特点，这样应用程序就不必关注这些设备的低层差别。RAW I/O或文件系统访问

  **内存映射文件访问是建立在块设备驱动程序之上的**。内存映射接口不是提供read和write操作，而是提供通过内存中的字节数组来访问磁盘存储。

* 字符设备包括键盘、鼠标、串行口

  应用程序可以get或put字符。在此基础上，可以构造库以提供具有**缓冲和编辑功能**的按行访问。

##### 网络设备

**网络I/O的性能与访问特点与磁盘I/O相比有很大差别**，绝大多数操作系统所提供的网络I/O接口也不同于磁盘的read-write-seek接口。许多OS所提供的是网络套接字接口。

套接字接口还提供了select函数，**以管理一组套接字**。调用select可以得知哪个套接字已有接收数据需要处理，哪个套接字已有空间可以接收数据以便发送。

##### 时钟与定时器

提供以下三个基本函数

* 获取当前时间
* 获取已经逝去的时间
* 设置定时器以在T时触发操作X

测量逝去时间和触发器操作的硬件称为可编程间隔定时器（programmable interval timer）

可被设置为等待一定的时间，然后触发中断；也可设置成一次或重复多次以产生定时中断

##### 阻塞和非阻塞I/O

* 阻塞 － 进程悬挂直到I/O完成为止

  容易使用与理解

  对某些需求难以满足

* 非阻塞 － I/O调用立刻返回

  用户接口，数据复制（缓冲I/O)

  通过多线程实现

  立刻返回读或写的字节数

异步 － 进程与I/O同时运行

难以使用

当I/O完成时，I/O系统发送信号通知进程

非阻塞与异步系统调用的差别是非阻塞read调用会马上返回，其所读取的数据可以等于或少于所要求的，或为零。异步read调用所要求的传输应完整地执行，其具体执行可以是将来某个特定时间。

#### I/O子系统

内核提供了许多与I/O有关的服务。许多服务如调度、缓冲、高速缓冲、假脱机、设备预留及错误处理是由**内核** **I/O子系统提供的**，并建立在**硬件**和**设备驱动程序**结构之上。

##### I/O调度

**调度**一组I/O请求就是确定一个好的顺序来执行这些请求。调度能改善系统整体性能，能在进程之间公平地共享设备访问，能减少I/O完成所需要的平均等待时间。

假设磁头位于磁盘开始处，三个应用程序向该磁盘发布阻塞读调用。应用程序1需要磁盘结束部分的块，应用程序2需要磁盘开始部分的块，应用程序3需要磁盘中间部分的块。OS如果按2、3、1的顺序处理，则可以减低磁头所需移动的距离。按这种方法来重新安排服务顺序就是I/O调度的核心。

操作系统开发人员通过为每个设备维护一个请求队列来实现调度。I/O调度重新安排队列顺序以改善系统总体效率和应用程序的平均相应时间。

操作系统可以试图公平，这样没有应用程序会得到不良的服务。

##### 缓冲

缓冲 － 用来保存在两设备之间或在设备和应用程序之间所传输数据的内存区域。

采用缓冲的三个理由：

* 处理设备速度的差异。如调制解调器的速度与硬盘的速度的差异。

* 处理设备传输大小的差异。如计算机网络中，缓冲常常用来处理消息的分段和重组。

* 维护应用程序的“拷贝语义”。

  “拷贝语义”示例：假如某应用程序需要将缓冲区的数据写入到磁盘。它可以调用write系统调用，并给出缓冲区的指针和表示所写字节数量的整数。当系统调用返回时，如果应用程序改变了缓冲区的内容，那么如何呢？根据“拷贝语义”，操作系统保证要写入磁盘的数据就是write系统调用发生时的版本，而无需顾虑应用程序缓冲区随后发生的变化。

##### 高速缓存

高速缓存（cache）：是可以保留数据拷贝的高速内存。 

缓冲与高速缓存的差别是缓冲只是**保留数据**仅有的一个现存拷贝，而根据定义高速缓存只是提供了一个驻留在其他地方的数据的一个高速拷贝。

##### 假脱机与设备预留

假脱机（spool） － 用来保存设备输出的缓冲，这些设备如打印机不能接收交叉的数据流。

操作系统通过截取对打印机的输出来解决这一问题。应用程序的输出先是假脱到一个独立的磁盘文件上。当应用程序完成打印时，假脱机系统将相应的待送打印机的**假脱机文件**进行排队。假脱机系统一次拷贝一个已排队的假脱机文件到打印机上。

设备预留 － 提供设备的互斥访问

* 分配与释放系统调用
* 谨防死锁

预留：亦即为某进程保留该设备的使用权，在该进程获得运行之前，其他申请该设备的进程将得不到使用权。（此含义非常类似与**阻塞等待**）

##### 错误处理

**OS可以对短暂出错进行弥补**。例如：磁盘read出错可以导致read重试，网络send出错可以导致resend（如果协议允许）。但是如果某个重要系统组件出现了永久错误，那么OS就不可能从中恢复。

当I/O请求失败后，多数返回一个错误号或错误码；系统错误日志保存问题的详细报告

内核需要保留I/O组件使用的状态信息，包括打开文件表，网络连接，字符设备状态等。许多复杂的数据结构用来跟踪缓冲，内存分配，及“脏”块。某些OS用面向对象的方法和消息传递的方法来实现I/O

##### I/O保护

#### 性能

减少上下文切换（context switch）的次数

减少设备和应用程序之间传递数据时在内存中的数据拷贝次数

使用大传输、智能控制器及轮流检测来减少中断频率。

通过采用DMA智能控制器和通道来为主CPU承担简单数据拷贝，以增加并发。

平衡CPU，内存子系统，总线和I/O的性能，因为任何一处的过载都会引起其他部分空闲。

### 保护

操作系统中的进程必须保护加以保护，使其免受其他进程活动的干扰。

确保只有从操作系统中获得了恰当授权的进程才可以操作相应的文件、内存段、处理器和其他资源。

**保护是指一种控制程序、进程或用户对计算机系统资源的访问的机制**。这个机制必须为强加控制提供一种规格说明方法和一种强制执行方法。

#### 保护目标

防止用户有意地、恶意地违反访问约束；

确保系统中活动的程序组件只以同规定的策略相一致的方式使用系统资源。

#### 保护域

一个计算机系统是进程和对象的集合。

对象分为硬件对象（如处理器、内存段、打印机、磁盘和磁带驱动器）和软件对象（如文件、程序和信号），每个对象有一个唯一的名字；用户只能通过定义好的有意义的操作来访问对象。

进程只能访问那些已经获得了授权的资源。在任何时候，进程只能访问完成现阶段的任务所需要的资源，这个要求常被称为需要则知道原则。

假定一个进程只在一个保护域内操作，该保护域指定了进程可以访问的资源。每个域定义了一个集合，集合的元素是对象和运用于集合中每一个对象上的操作的类型。在一个对象上执行一个操作的权限是一种访问权限。

**一个域是一个访问权限的集合，每个访问权限是一个有序对<对象名，权利集合>。**

域之间允许存在交集，它们可以共享访问权限。

上图中，有三个保护域：D1、D2、D3。访问权限<O4,{print}>是由D2和D3共享的，也就是说，运行在D2或D3上的任意一个进程都有打印对象O4的权限。另外，一个进程只有运行在D1上时才能读写对象O1，只有域D3中运行的进程才能执行对象O1。

一个域和一个进程之间的关联可以是静态的，也可以是动态的。如果进程和域之间的关联固定不变，并且不想违反需要则知道原则，那么必须保证存在一个能够改变域的内容的机制。如果关联是动态的，则必须提供一个允许进程在域之间切换的机制。

一个域可以通过以下几种不同的途径来实现：

* 每个用户是一个域。可以访问的对象集取决于用户的身份。
* 每个进程是一个域。对象集的访问取决于进程的身份。
* 每个过程是一个域。可以访问的对象集对应这个过程中所定义的局部变量。

在UNIX下，域和用户是关联的。域切换会配合用户身份的临时切换。

每个文件都有一个所有者身份标识和一个域位（setid bit）与它相关联。

当一个用户（用户ID为A）开始执行一个属于B的文件时，如果此时B的关联域位是关闭的，那么该进程的用户ID会被设置成A；如果这个设置用户ID位是开启的，那么该进程的用户ID应该设置为文件的所有者：B。如果进程退出，这个临时的用户ID的变动也就随之结束。

示例：

用户不用自己写网络程序，也同样能访问网络。

#### 访问矩阵

可以将保护模型抽象为一个矩阵，称之为访问矩阵。矩阵的行代表域，矩阵的列代表对象。访问条目（i，j）定义了在域Di中执行的进程在对象Oj上可以调用的操作的集合。

进程必须能够在域之间切换。当需要将一个进程从一个域切换到另一个域时，其实是在一个对象上执行一个操作（切换）。可以将域作为对象添加到访问矩阵，这样就可以控制域切换了。当且仅当访问权限switch∈ access(i,j) 时，才允许从域Di到域Dj的切换发生。

要想访问矩阵的条目内容提供受控更改需要三个额外的操作：拷贝、所有者和控制。从访问矩阵的一个域中拷贝一个访问权限到另一个域，这种权限用附加在访问权限后面的“*”标记。拷贝权限只允许在定义了该权限的列内拷贝访问权限。

同样需要提供这样一种机制，它允许添加新的权限或者删除已有权限。由所有者权限控制这些操作。如果access(i,j)包含所有者权限，那么一个在域Di执行的进程就可以添加和删除列j中的任意一个权限。

还需要一个允许在行中修改条目的机制。控制权限只适用于域对象。如果access(i,j)包含控制权限，那么在域Di中执行的进程可以从行j中删除任意一个访问权限。

Mechanism(怎样做)

* 操作系统提供访问矩阵+规则。
* 确保矩阵仅由授权代理操作，并确保规则得到严格执行。

Policy(做什么)

* 用户指示策略。
* 谁可以访问什么对象和什么模式。

#### 访问矩阵的实现

#### 全局表

一般情况下，访问矩阵是一个稀疏矩阵，也就是说大多数条目都是空的。

一个全局表是一个三元关系<域，对象，权限集合>的集合。

当一个操作M在域Di中作用于对象Oj时，系统就在全局表中查找三元关系 <Di, Oj, Rk>，查找条件是M∈Rk。

缺点：

* 这张表通常很大。
* 额外的I/O开销。

#### 对象的访问列表

访问矩阵中的每个列都可以被实现成一个对象的访问列表。每个对象的列表由有序对<域， 权限集>组成，这些有序对为该对象定义了所有着非空访问权限集合的域。

可以对这个方法作一些扩充，定义一个列表和一个缺省的访问权限集合。

当用户想在域Di中对对象Oj执行操作M时，系统开始在访问权限列表中为对象Oj查找条目<Di,Rk>，查找条件是M∈Rk。

为了提高效率，通常是在查找缺省集合失败之后才查找访问列表。

### 安全

#### 安全问题

安全需要考虑系统运行的外部环境，防止它们：

* 被未经授权者访问
* 被恶意地更改或破坏
* 被意外地引入不一致问题

防止意外误用比防止恶意破坏要容易得多。

要保护系统，必须在4个层次上采取安全机制：

* 物理：必须采取物理措施保护计算机系统的站点，防止入侵者强行地或秘密地侵入。
* 人：必须谨慎筛选用户，减少授权用户授予入侵者访问权限的机会。
* 网络：现代系统中的许多计算机数据都在私人租用的线、共享的线上传播。中途截取这些数据的危害和入侵计算机的危害是等同的。
* 操作系统：操作系统必须防止自身遭受意外的或者有意的安全破坏。

操作系统的一个主要安全问题就是验证。

验证用户身份的最常用的方法就是使用密码，密码可以被看做钥匙或者权限的特例。例如：一个密码可以被关联到每个资源（例如文件）。不同的密码可能会关联到不同的访问权限。

密码容易理解和使用，因而应用的特别多。有两种常见的猜测密码的方法：

* 第一种是用户经常使用一些明显的信息。
* 另一种是使用暴力。

怎样在计算机中秘密地存储密码？

##### 加密

UNIX系统会对密码进行加密，这样就不再需要秘密地保存密码列表。这个方法的缺陷是系统不再全权控制密码。许多UNIX系统只注重密码的前8个字符，因此用户要充分利用可用的密码空间。

##### 一次性

为了避免密嗅探或偷窥，系统可以使用配对密码集合。一个会话开始时，系统随机选择并提供一个密码对的一部分，用户必须提供另外一个部分。在这个系统中，由系统挑战用户，并且要求用户提供正确的答案来响应挑战。

实现

* 可以将这种算法扩展为使用一个算法作为密码。例如，算法可以是一个整数函数。
* 系统选择一个随机的整数并向用户展示该整数。
* 用户用这个整数函数计算系统提供的整数，并将正确结果回复给系统。
* 系统自身也用函数计算该整数，如果两者的结果匹配，就允许访问。

#### 程序威胁

##### 特洛伊木马

一个误用自身环境的代码段被称为特洛伊木马。利用系统提供的一种机制：允许程序作者以外的用户运行程序。

例如：一个文本编辑器，它可能允许根据关键字搜索要编辑的文件。如果有文件被搜索到，就会将整个文件的内容拷贝到一个文本编辑器的创建者可以访问到的特定区域中。

特洛伊木马问题有一个变种，就是模仿一个登录程序。如果操作系统采用一个不可捕获的系列键，CTRL+ALT+DEL，可以击败模拟登录程序的攻击。

##### 后门

特定的用户ID或者密码，让这个特定的用户避开正常的安全程序。

可以在一个编译器中包含一个巧妙的后门。

##### 栈和缓冲区溢出

这种攻击就是利用程序中的一个错误。攻击者编写一个程序来完成以下几项任务：

* 使一个输入域、命令行的参数或者一个输入缓冲区溢出。
* 覆写栈内当前的返回地址。
* 为紧接的栈空间写一段代码，这段代码包括了攻击者想要执行的命令。

#### 系统威胁

蠕虫是一个利用繁殖机制破坏系统性能的进程。蠕虫大量产生自身的拷贝，耗尽系统资源，甚至可能让其他进程停止使用资源。

病毒是一个内嵌到合法程序中的代码段。病毒的传播通常有两种途径：一是用户从公共计算机中下载带病毒的程序；二是交换已感染的磁盘。

拒绝服务，它不会从系统中窃取信息或者盗用资源，但它会阻止系统或者设备的合法使用。

#### 威胁监测

检查可疑的活动模式-即，几次不正确的密码尝试可能会发出密码猜测的信号。

审核日志-记录访问对象的所有访问的时间、用户和类型;有助于从违规行为中恢复，并制定更好的安全措施。

定期扫描系统以寻找安全漏洞;当计算机相对未使用时完成。

检查：

* 短的或者容易猜中的密码
* 未授权的特权程序，如设置用户ID的程序
* 系统目录中的未授权程序
* 意外的长时间运行程序
* 用户和系统目录下不恰当的目录保护
* 对系统数据文件的不恰当保护（如密码文件）
* 程序搜索路径中的不安全入口
* 通过校验和的值发现的系统程序的改变
* 意料之外的或隐藏的网络监护程序

防火墙是一台夹在可靠系统和不可靠系统之间的计算机或者路由器。它限制这两个安全域之间的网络访问，并监控和记录所有的连接。它还会根据源地址或者目的地址、源端口或目的端口或链接的方向来限制连接。

一道防火墙可以将一个网络分离成几个域：

* 不可靠的域：Internet。

* 非军事区：半可靠和半安全的网络。

* 由公司的计算机组成的局域网。

允许以下两类连接：

1.从因特网到DMZ计算机的连接；

2.从公司计算机到因特网的连接。

禁止以下两类连接：

从因特网或者DMZ到公司计算机的连接。

以下为可选项:

可能允许DMZ和一台或多台公司计算机之间的受控链接。

##### 入侵检测

入侵检测主要是检测对计算机系统的入侵企图，并且启动对入侵的恰当的响应。

基于签名的检测：在系统输入和网络传输中检测预示着攻击的特征行为模式。

异常检测：试图检测系统中的异常行为。异常检测可以检测出以前不知道的入侵方法。

* 审计和记录

  审计跟踪处理是一个常用的入侵检测方法。在这个方法中，把与安全相关的事件都记录到一个审计跟踪表中，然后将记录和攻击签名匹配。

* 系统调用监控监控的是系统调用进程，在一个进程偏离预期的系统调用行为时进行实时监测。程序的“常用”的系统调用序列是通过在各输入上运行程序后得出的。

这个表用于指出对于每个系统调用，有哪些系统调用可以跟它的距离为1、2等，直到k的位置后面。存储这张表。以后执行这个程序时，就将系统调用列表和这张表比较，寻找差异。